# 소개
:label:`chap_introduction`

최근까지 우리가 매일 상호 작용하는 거의 모든 컴퓨터 프로그램은 소프트웨어 개발자가 첫 번째 원칙에서 코딩했습니다.전자 상거래 플랫폼을 관리하는 애플리케이션을 작성하고 싶다고 가정 해 보겠습니다.문제를 숙고하기 위해 화이트보드를 몇 시간 동안 모은 후 다음과 같이 보일 수 있는 광범위한 작업 솔루션을 생각해 낼 것입니다. (i) 사용자가 웹 브라우저 또는 모바일 애플리케이션에서 실행되는 인터페이스를 통해 애플리케이션과 상호 작용합니다. (ii) 애플리케이션상용 등급의 데이터베이스 엔진과 상호 작용하여 각 사용자의 상태를 추적하고 과거 거래 기록을 유지합니다. (iii) 애플리케이션의 핵심에서 애플리케이션의*비즈니스 논리* (*두뇌*) 는 당사의 적절한 조치를 체계적으로 자세히 설명합니다.프로그램은 생각할 수 있는 모든 상황을 고려해야 합니다.

애플리케이션의 두뇌를 구축하려면 발생할 것으로 예상되는 모든 코너 사례를 단계별로 살펴보고 적절한 규칙을 고안해야 합니다.고객이 클릭하여 장바구니에 품목을 추가할 때마다 아마존은 장바구니 데이터베이스 테이블에 항목을 추가하여 해당 사용자의 ID를 요청된 제품의 ID와 연결합니다.처음에는 완전히 올바른 것을 얻은 개발자는 거의 없지만 (꼬임을 해결하기 위해 몇 가지 테스트 실행이 필요할 수 있음), 대부분의 경우 첫 번째 원칙에서 이러한 프로그램을 작성하고 자신있게 시작할 수 있습니다.
*실제 고객을 만나기 전에*.
종종 새로운 상황에서 작동하는 제품과 시스템을 구동하는 첫 번째 원칙에서 자동화 시스템을 설계하는 우리의 능력은 놀라운 인지적 위업입니다.또한 100달러 $\%$의 시간 동안 작동하는 솔루션을 고안할 수 있다면 머신 러닝을 사용하지 않아야 합니다.

다행스럽게도 성장하는 기계 학습 과학자 커뮤니티의 경우 자동화하려는 많은 작업이 인간의 독창성에 쉽게 맞지 않습니다.아는 가장 똑똑한 마음으로 화이트보드 주위에 모여 있다고 상상해보십시오. 하지만 이번에는 다음 문제 중 하나를 해결하고 있습니다.

* 지리 정보, 위성 이미지 및 과거 날씨의 후행 창을 통해 내일의 날씨를 예측하는 프로그램을 작성하십시오.
* 자유 형식 텍스트로 표현된 질문을 받아 올바르게 답변하는 프로그램을 작성합니다.
* 주어진 이미지가 포함 된 모든 사람을 식별하고 각 이미지 주위에 윤곽선을 그릴 수있는 프로그램을 작성하십시오.
* 사용자가 즐길 가능성이 있지만 자연스럽게 탐색하는 과정에서 접할 가능성이 낮은 제품을 사용자에게 제공하는 프로그램을 작성하십시오.

이러한 각각의 경우에 엘리트 프로그래머조차도 처음부터 솔루션을 코딩할 수 없습니다.그 이유는 다를 수 있습니다.때때로 우리가 찾고있는 프로그램은 시간이 지남에 따라 변하는 패턴을 따르기 때문에 프로그램이 적응해야 할 때가 있습니다.다른 경우에는 관계 (예: 픽셀 및 추상 범주 간) 가 너무 복잡하여 눈이 작업을 쉽게 관리하더라도 의식적인 이해를 넘어서는 수천 또는 수백만 번의 계산이 필요할 수 있습니다.
*머신 러닝*은 강력한 연구입니다
경험을 통해 배울 수 있는 테크닉입니다.머신 러닝 알고리즘은 일반적으로 관찰 데이터 또는 환경과의 상호 작용의 형태로 더 많은 경험을 축적함에 따라 성능이 향상됩니다.개발자가 소프트웨어를 업데이트 할 때가되었다고 스스로 배우고 결정할 때까지 얼마나 많은 경험이 발생하더라도 동일한 비즈니스 로직에 따라 수행되는 결정론적 전자 상거래 플랫폼과 대조하십시오.이 책에서는 머신 러닝의 기초를 가르치고, 특히 컴퓨터 비전, 자연어 처리, 의료 및 유전체학과 같은 다양한 분야에서 혁신을 주도하는 강력한 기술인*딥 러닝*에 중점을 둡니다.

## 동기를 부여하는 예

글을 쓰기 시작하기 전에, 이 책의 저자는 많은 노동력과 마찬가지로 카페인을 섭취해야했습니다.우리는 차 안에서 뛰어 올라 운전을 시작했습니다.Alex는 iPhone을 사용하여 “Hey Siri”를 호출하여 휴대 전화의 음성 인식 시스템을 깨웠습니다.그런 다음 Mu는 “블루 보틀 커피 숍으로가는 길”을 명령했습니다.전화는 그의 명령의 기록을 빠르게 표시했습니다.또한 길 찾기를 요청하고 요청을 이행하기 위해지도 애플리케이션 (앱) 을 출시했음을 인식했습니다.지도 앱이 실행되면 여러 경로를 식별했습니다.각 경로 옆에는 예상 대중 교통 시간이 표시되었습니다.교육적 편의를 위해 이 이야기를 제작했지만 단 몇 초 만에 스마트폰과의 일상적인 상호 작용이 여러 기계 학습 모델에 참여할 수 있음을 보여줍니다.

“Alexa”, “OK Google”, “Hey Siri”와 같은*깨우기 단어*에 응답하는 프로그램을 작성한다고 상상해보십시오.:numref:`fig_wake_word`에 나와 있는 것처럼 컴퓨터와 코드 편집기만으로 방에서 직접 코딩해 보십시오.첫 번째 원칙에서 그런 프로그램을 어떻게 작성하겠습니까?생각해 봐... 문제는 힘들다.매초 마이크는 약 44000개의 샘플을 수집합니다.각 샘플은 음파의 진폭을 측정 한 것입니다.원시 오디오 스니펫에서 스니펫에 웨이크 워드가 포함되어 있는지 여부에 대한 확실한 예측 $\{\text{yes}, \text{no}\}$에 이르기까지 안정적으로 매핑할 수 있는 규칙은 무엇입니까?막혔더라도 걱정하지 마십시오.이러한 프로그램을 처음부터 작성하는 방법도 모릅니다.이것이 바로 머신 러닝을 사용하는 이유입니다.

![Identify a wake word.](../img/wake-word.svg)
:label:`fig_wake_word`

여기 트릭이 있습니다.종종 입력에서 출력으로 매핑하는 방법을 컴퓨터에 명시 적으로 알려주는 방법을 모르는 경우에도 그럼에도 불구하고 우리는 스스로 인지 적 위업을 수행 할 수 있습니다.즉, “Alexa”라는 단어를 인식하도록 컴퓨터를 프로그래밍하는 방법을 모르더라도 스스로 인식 할 수 있습니다.이 능력으로 무장하면 오디오의 예가 포함 된 거대한* 데이터 세트*를 수집하고 깨우기 단어를 포함하지 않는 오디오에 레이블을 지정할 수 있습니다.기계 학습 접근 방식에서는 시스템을 설계하려고 시도하지 않습니다.
*깨우기 단어를 인식하기 위해 명시적으로*를 사용합니다.
대신 여러 매개 변수*에 의해 동작이 결정되는 유연한 프로그램을 정의합니다.그런 다음 데이터 세트를 사용하여 관심있는 작업의 일부 성능 측정과 관련하여 프로그램의 성능을 향상시키는 최상의 매개 변수 집합을 결정합니다.

매개 변수를 돌려서 프로그램의 동작을 조작 할 수있는 노브로 생각할 수 있습니다.매개 변수를 고정하면 프로그램을*모델*이라고합니다.매개 변수를 조작하는 것만으로 생성 할 수있는 모든 개별 프로그램 (입력-출력 매핑) 세트를 모델의*패밀리*라고합니다.그리고 데이터 세트를 사용하여 매개 변수를 선택하는 메타 프로그램을*학습 알고리즘*이라고합니다.

학습 알고리즘을 사용하기 전에 문제를 정확하게 정의하고 입력과 출력의 정확한 특성을 고정하고 적절한 모델 제품군을 선택해야 합니다.이 경우 모델은 오디오 스니펫을*입력*으로 수신하고 모델은 $\{\text{yes}, \text{no}\}$ 중에서 선택을*출력*으로 생성합니다.모든 것이 계획대로 진행된다면 일반적으로 스니펫에 깨우기 단어가 포함되어 있는지 여부에 대한 모델의 추측이 정확합니다.

올바른 모델 제품군을 선택하면 “Alexa”라는 단어를들을 때마다 모델이 “예”를 실행하도록 노브 설정이 하나 있어야합니다.웨이크 워드의 정확한 선택은 임의적이기 때문에 손잡이의 다른 설정을 통해 “살구”라는 단어를 들었을 때만 “예”가 발생할 수있는 충분히 풍부한 모델 패밀리가 필요할 것입니다.동일한 모델 제품군이 직관적으로 유사한 작업으로 보이기 때문에 “Alexa”인식 및 “살구”인식에 적합해야 할 것으로 기대합니다.그러나 근본적으로 다른 입력 또는 출력을 처리하려는 경우, 예를 들어 이미지에서 캡션으로 또는 영어 문장에서 중국어 문장으로 매핑하려는 경우 완전히 다른 모델 제품군이 필요할 수 있습니다.

짐작할 수 있듯이 모든 노브를 무작위로 설정하면 모델이 “Alexa”, “Apricot”또는 다른 영어 단어를 인식하지 못할 것입니다.기계 학습에서*학습*은 모델에서 원하는 동작을 강요하는 노브의 올바른 설정을 발견하는 프로세스입니다.즉, 데이터를 사용하여 모델을 학습*훈련*합니다.:numref:`fig_ml_loop`에서 볼 수 있듯이 교육 과정은 일반적으로 다음과 같습니다.

1. 유용한 작업을 수행할 수 없는 임의로 초기화된 모델로 시작합니다.
1. 일부 데이터 (예: 오디오 스니펫 및 해당 $\{\text{yes}, \text{no}\}$ 레이블) 를 가져옵니다.
1. 노브를 조정하여 이러한 예제와 관련하여 모델이 덜 빨아들이도록 합니다.
1. 모델이 멋질 때까지 2단계와 3단계를 반복합니다.

![A typical training process.](../img/ml-loop.svg)
:label:`fig_ml_loop`

요약하면, 웨이크 워드 인식기를 코딩하는 대신, 레이블이 지정된 큰 데이터 세트를 제시하면 웨이크 워드를 인식하도록 학습* 할 수있는 프로그램을 코딩합니다.데이터 세트를*데이터 프로그래밍*으로 제시하여 프로그램의 동작을 결정하는 이러한 동작을 생각할 수 있습니다.즉, 기계 학습 시스템에 고양이와 개에 대한 많은 예를 제공하여 고양이 탐지기를 “프로그래밍”할 수 있습니다.이런 식으로 탐지기는 결국 고양이 인 경우 매우 큰 양수, 개인 경우 매우 큰 음수, 확실하지 않은 경우 0에 가까운 것을 방출하는 법을 배우게되며, 이는 기계 학습이 할 수있는 것의 표면을 거의 긁지 않습니다.나중에 자세히 설명하겠습니다. 딥 러닝은 기계 학습 문제를 해결하는 데 널리 사용되는 많은 방법 중 하나에 불과합니다.

## 주요 구성 요소

웨이크 워드 예제에서 오디오 스 니펫과 바이너리 레이블로 구성된 데이터 세트를 설명하고 스 니펫에서 분류로의 매핑을 근사하도록 모델을 훈련시키는 방법을 손으로 물결 모양으로 이해했습니다.레이블이 알려진 예제로 구성된 데이터 세트가 주어진 경우 알려진 입력을 기반으로 지정된 알려지지 않은 레이블을 예측하려고 시도하는 이러한 종류의 문제를*지도 학습*이라고합니다.이는 여러 종류의 기계 학습 문제 중 하나에 불과합니다.나중에 다양한 기계 학습 문제에 대해 자세히 살펴보겠습니다.먼저, 어떤 종류의 기계 학습 문제를 겪고 있더라도 우리를 따라갈 몇 가지 핵심 구성 요소에 대해 더 자세히 설명하고자합니다.

1. 우리가 배울 수 있는*데이터*.
1. 데이터를 변환하는 방법에 대한*모델*.
1. 모델이 얼마나 잘 (또는 나쁘게) 하고 있는지를 정량화하는*목적 함수*.
1. 목적 함수를 최적화하기 위해 모델의 모수를 조정하는*알고리즘*입니다.

### 데이터

데이터 없이는 데이터 과학을 할 수 없다는 것은 말할 필요도 없습니다.우리는 정확히 데이터를 구성하는 것이 무엇인지 숙고하면서 수백 페이지를 잃을 수도 있지만, 지금은 실용적인 측면에서 잘못하고 관심을 가져야 할 주요 속성에 초점을 맞출 것입니다.일반적으로 예제 모음에 관심이 있습니다.데이터를 유용하게 사용하려면 일반적으로 적절한 수치 표현을 제시해야 합니다.각*예제* (또는*데이터 요소*, *데이터 인스턴스*, *샘플*) 는 일반적으로*특징* (또는*공변량*) 이라는 속성 집합으로 구성되며, 이 속성 집합에서 모델을 예측해야 합니다.위의 지도 학습 문제에서 예측할 것은*label* (또는*target*) 로 지정된 특수 속성입니다.

이미지 데이터로 작업하는 경우 각 개별 사진이 예제를 구성 할 수 있으며 각 사진은 각 픽셀의 밝기에 해당하는 정렬 된 숫자 값 목록으로 표시됩니다.$200\times 200$ 컬러 사진은 각 공간 위치에 대한 빨강, 녹색 및 파랑 채널의 밝기에 해당하는 $200\times200\times3=120000$ 숫자 값으로 구성됩니다.또 다른 전통적인 과제에서는 연령, 활력 징후 및 진단과 같은 표준 기능을 고려할 때 환자의 생존 여부를 예측하려고 할 수 있습니다.

모든 예제가 동일한 수의 숫자 값으로 특징 지워지면 데이터가 고정 길이 벡터로 구성되고 벡터의 일정한 길이를 데이터의*차원성*으로 설명합니다.상상할 수 있듯이 고정 길이는 편리한 속성이 될 수 있습니다.현미경 이미지에서 암을 인식하도록 모델을 훈련시키고 싶다면 고정 길이 입력은 걱정할 것이 하나 줄어든다는 것을 의미합니다.

그러나 모든 데이터를 다음과 같이 쉽게 표현할 수 있는 것은 아닙니다.
*고정 길이* 벡터.
현미경 이미지가 표준 장비에서 나올 것으로 예상할 수 있지만 인터넷에서 채굴된 이미지가 모두 동일한 해상도나 모양으로 표시될 것이라고 기대할 수는 없습니다.이미지의 경우 모든 이미지를 표준 크기로 자르는 것을 고려할 수 있지만, 이 전략은 지금까지만 얻을 수 있습니다.잘린 부분의 정보가 손실될 위험이 있습니다.또한 텍스트 데이터는 고정 길이 표현에 훨씬 더 완고하게 저항합니다.아마존, IMDB 및 트립어드바이저와 같은 전자 상거래 사이트에 남겨진 고객 리뷰를 고려하십시오.일부는 짧습니다. “악취가 난다!”.다른 사람들은 페이지를 위해 방황합니다.기존 방법에 비해 딥 러닝의 주요 이점 중 하나는 최신 모델이*다양한 길이* 데이터를 처리할 수 있는 비교의 우아함입니다.

일반적으로 데이터가 많을수록 작업이 더 쉬워집니다.데이터가 더 많으면 더 강력한 모델을 훈련시킬 수 있고 미리 생각한 가정에 덜 의존할 수 있습니다.(비교적) 작은 데이터에서 빅 데이터로의 정권 변화는 현대 딥 러닝의 성공에 큰 기여를 하고 있습니다.요점을 되찾기 위해 딥 러닝에서 가장 흥미로운 모델 중 다수가 대규모 데이터 세트 없이는 작동하지 않습니다.다른 일부는 소규모 데이터 체제에서 작동하지만 기존 접근 방식보다 낫지 않습니다.

마지막으로 많은 양의 데이터를 보유하고 영리하게 처리하는 것만으로는 충분하지 않습니다.*올바른* 데이터가 필요합니다.데이터가 실수로 가득 차거나 선택한 피처가 목표 관심 수량을 예측하지 못하면 학습이 실패합니다.상황은 진부한 표현으로 잘 포착됩니다.
*쓰레기 투입, 쓰레기 배출*.
또한 예측 성능 저하가 유일한 잠재적 결과는 아닙니다.예측 정책, 이력서 심사 및 대출에 사용되는 위험 모델과 같은 기계 학습의 민감한 응용 분야에서는 가비지 데이터의 결과에 특히주의해야합니다.한 가지 일반적인 고장 모드는 훈련 데이터에서 일부 그룹의 사람들이 표시되지 않는 데이터셋에서 발생합니다.이전에는 검은 피부를 본 적이 없었던 야생에서 피부암 인식 시스템을 적용한다고 상상해보십시오.데이터가 단순히 일부 그룹을 과소 나타내는 것이 아니라 사회적 편견을 반영하는 경우에도 실패가 발생할 수 있습니다.예를 들어 과거의 채용 결정을 사용하여 이력서를 선별하는 데 사용될 예측 모델을 학습하는 경우 기계 학습 모델은 실수로 과거의 불의를 포착하고 자동화할 수 있습니다.데이터 과학자가 적극적으로 음모를 꾸미거나 인식하지 않아도 이 모든 일이 발생할 수 있습니다.

### 모델들

대부분의 기계 학습에는 어떤 의미에서 데이터를 변환하는 작업이 포함됩니다.사진을 수집하고 웃음을 예측하는 시스템을 구축하고 싶을 수도 있습니다.또는 센서 판독값 세트를 수집하고 판독값이 얼마나 정상인지 비정상적인지 예측할 수 있습니다.*model*은 한 유형의 데이터를 수집하고 다른 유형의 예측을 뱉어내는 계산 기계를 나타냅니다.특히 데이터에서 추정할 수 있는 통계 모델에 관심이 있습니다.단순한 모델은 적절하게 간단한 문제를 완벽하게 해결할 수 있지만, 이 책에서 우리가 중점을 둔 문제는 고전적 방법의 한계를 확장합니다.딥 러닝은 주로 중점을 둔 강력한 모델 세트에 의해 고전적 접근 방식과 차별화됩니다.이러한 모델은 위에서 아래로 연결된 데이터의 여러 연속 변환으로 구성되므로*deep learning*이라는 이름이 붙습니다.심층 모델을 논의하는 과정에서 좀 더 전통적인 방법에 대해서도 논의 할 것입니다.

### 목적 함수

앞서 우리는 경험을 통한 학습으로 기계 학습을 도입했습니다.여기에서*학습*한다는 것은 시간이 지남에 따라 어떤 과제에서 향상되는 것을 의미합니다.그러나 개선을 구성하는 것이 무엇인지 누가 말할까요?모델 업데이트를 제안 할 수 있으며 일부 사람들은 제안 된 업데이트가 개선 또는 감소를 구성했는지 여부에 동의하지 않을 수 있습니다.

학습 기계의 공식적인 수학적 시스템을 개발하기 위해서는 모델이 얼마나 좋은지 (또는 나쁜지) 공식적인 측정이 필요합니다.머신 러닝과 최적화에서는 좀 더 일반적으로*목적 함수*라고 부릅니다.관례에 따라 우리는 일반적으로 낮을수록 더 나은 목적 함수를 정의합니다.이것은 단지 관례에 불과합니다.더 높은 것이 더 좋은 함수를 취하여 질적으로 동일하지만 부호를 뒤집어 낮을수록 더 좋은 새로운 기능으로 바꿀 수 있습니다.낮을수록 좋기 때문에 이러한 함수를 호출하는 경우가 있습니다.
*손실 함수*.

숫자 값을 예측하려고 할 때 가장 일반적인 손실 함수는*제곱 오류*, 즉 예측과 실측 간의 차이의 제곱입니다.분류의 경우 가장 일반적인 목표는 오류율, 즉 예측이 근거 진실과 일치하지 않는 예제의 일부를 최소화하는 것입니다.일부 대물렌즈 (예: 제곱 오차) 는 쉽게 최적화할 수 있습니다.기타 (예: 오류율) 는 차별화되지 않거나 기타 합병증으로 인해 직접 최적화하기가 어렵습니다.이러한 경우에는*대리 목표*를 최적화하는 것이 일반적입니다.

일반적으로 손실 함수는 모델의 매개 변수와 관련하여 정의되며 데이터 세트에 따라 다릅니다.훈련을 위해 수집된 몇 가지 예제로 구성된 집합에서 발생하는 손실을 최소화하여 모델 파라미터의 최적 값을 학습합니다.그러나 훈련 데이터를 잘 수행한다고해서 보이지 않는 데이터에 대해 잘 수행된다는 보장은 없습니다.따라서 일반적으로 사용 가능한 데이터를*훈련 데이터 세트* (또는 모델 매개 변수 피팅을위한*훈련 세트*) 와*테스트 데이터 세트* (또는 평가를 위해 유지된*테스트 세트*) 의 두 파티션으로 분할하여 두 파티션에서 모델이 어떻게 수행되는지를 보고합니다.교육 성과는 실제 최종 시험을 준비하는 데 사용되는 연습 시험에서 학생의 점수와 같다고 생각할 수 있습니다.결과가 고무적이더라도 최종 시험의 성공을 보장하지는 않습니다.즉, 테스트 성능이 훈련 성과와 크게 다를 수 있습니다.모델이 훈련 세트에서 잘 수행되지만 보이지 않는 데이터로 일반화하지 못하면 모델이*overfitting*이라고 말합니다.실생활에서 이것은 연습 시험에서 잘 수행함에도 불구하고 실제 시험을 치르는 것과 같습니다.

### 최적화 알고리즘

데이터 소스와 표현, 모델 및 잘 정의된 목적 함수가 확보되면 손실 함수를 최소화하기 위해 가능한 최상의 파라미터를 검색할 수 있는 알고리즘이 필요합니다.딥러닝에 널리 사용되는 최적화 알고리즘은*기울기 하강*이라는 접근법을 기반으로 합니다.간단히 말해, 각 단계에서 이 방법은 각 파라미터에 대해 해당 파라미터를 조금만 교란하면 훈련 세트 손실이 어떤 방향으로 이동하는지 확인합니다.그런 다음 손실을 줄일 수 있는 방향으로 매개변수를 업데이트합니다.

## 머신 러닝 문제의 종류

동기 부여 예제에서 깨우기 단어 문제는 기계 학습이 해결할 수 있는 많은 문제 중 하나에 불과합니다.책 전체에서 더 많은 문제에 대해 이야기 할 때 독자에게 더 많은 동기를 부여하고 공통 언어를 제공하기 위해 다음에는 기계 학습 문제의 샘플링이 나열되어 있습니다.우리는 데이터, 모델 및 교육 기술과 같은 앞서 언급 한 개념을 지속적으로 언급 할 것입니다.

### 지도 학습

지도 학습은 주어진 입력 특징이 있는 레이블을 예측하는 작업을 다룹니다.각 피처 - 레이블 쌍을 예라고 합니다.때로는 문맥이 명확할 때 해당 레이블을 알 수 없더라도 입력 모음을 지칭하기 위해*examples*라는 용어를 사용할 수 있습니다.우리의 목표는 모든 입력을 레이블 예측에 매핑하는 모델을 생성하는 것입니다.

이 설명을 구체적인 예로 들자면, 우리가 의료 분야에서 일하고 있다면 환자가 심장 마비를 앓을지 여부를 예측하고 싶을 것입니다.“심장 마비”또는 “심장 마비 없음”이라는 이러한 관찰이 우리의 레이블이 될 것입니다.입력 기능은 심박수, 이완기 혈압 및 수축기 혈압과 같은 활력 징후 일 수 있습니다.

매개 변수를 선택하기 위해 우리 (감독자) 가 레이블이 지정된 예제로 구성된 데이터 세트를 모델에 제공하기 때문에 감독이 시작됩니다. 여기서 각 예제는 지상 실측 레이블과 일치합니다.확률적 용어로, 우리는 일반적으로 입력 특징이 주어진 레이블의 조건부 확률을 추정하는 데 관심이 있습니다.머신러닝의 여러 패러다임 중 하나일 뿐이지 만, 지도 학습은 업계에서 기계 학습의 성공적인 응용 프로그램의 대부분을 차지합니다.부분적으로는 사용 가능한 특정 데이터 집합이 주어지면 알려지지 않은 무언가의 확률을 추정하는 것으로 많은 중요한 작업을 선명하게 설명 할 수 있기 때문입니다.

* 컴퓨터 단층 촬영 영상이 주어지면 암이 아닌 암을 예측합니다.
* 영어로 된 문장이 주어지면 프랑스어로 올바른 번역을 예측합니다.
* 이번 달의 재무 보고 데이터를 기반으로 다음 달 주식 가격을 예측합니다.

“입력 기능이 주어진 레이블 예측”이라는 간단한 설명으로도 지도 학습은 유형, 크기 및 입력 및 출력의 수에 따라 매우 다양한 형태를 취할 수 있으며 많은 모델링 결정이 필요할 수 있습니다.예를 들어, 다양한 모델을 사용하여 임의의 길이의 시퀀스를 처리하고 고정 길이 벡터 표현을 처리합니다.이 책 전체에서 이러한 많은 문제를 자세히 살펴볼 것입니다.

비공식적으로 학습 과정은 다음과 같습니다.먼저 기능이 알려진 대규모 예제 모음을 가져와 임의의 하위 집합을 선택하여 각각에 대한 실측 레이블을 얻습니다.때때로 이러한 라벨은 이미 수집된 데이터일 수 있습니다 (예: 환자가 다음 해에 사망했습니까?)다른 경우에는 데이터에 레이블을 지정하기 위해 사람의 주석자를 사용해야 할 수도 있습니다 (예: 이미지를 카테고리에 할당).이러한 입력과 해당 레이블이 함께 훈련 세트를 구성합니다.학습 데이터 세트를 데이터세트를 입력으로 받아 다른 함수, 즉 학습된 모델을 출력하는 함수인 지도 학습 알고리즘에 입력합니다.마지막으로, 출력값을 해당 레이블의 예측으로 사용하여 이전에 볼 수 없었던 입력을 학습된 모델에 제공할 수 있습니다.전체 프로세스는 :numref:`fig_supervised_learning`에서 그려집니다.

![Supervised learning.](../img/supervised-learning.svg)
:label:`fig_supervised_learning`

#### 회귀

아마도 머리를 감싸는 가장 간단한 지도 학습 과제는*회귀*일 것입니다.예를 들어 주택 판매 데이터베이스에서 수집한 데이터 집합을 생각해 보십시오.각 행이 다른 집에 해당하고 각 열이 집의 평방 피트 수, 침실 수, 욕실 수 및 도시 중심까지의 분 (도보) 과 같은 관련 속성에 해당하는 테이블을 만들 수 있습니다.이 데이터셋에서 각 예는 특정 주택이고 해당 특징 벡터는 테이블의 한 행이 됩니다.뉴욕이나 샌프란시스코에 거주하고 아마존, 구글, 마이크로소프트 또는 페이스북의 CEO가 아닌 경우 가정의 (평방 피트 수, 침실 수, 욕실 수, 도보 거리) 피처 벡터는 $[600, 1, 1, 60]$와 같이 보일 수 있습니다.그러나 피츠버그에 살고 있다면 $[3000, 4, 3, 10]$처럼 보일 수 있습니다.이와 같은 특징 벡터는 대부분의 고전적인 기계 학습 알고리즘에 필수적입니다.

문제를 회귀로 만드는 것은 실제로 출력입니다.새 주택 시장에 있다고 가정 해보십시오.위와 같은 일부 기능을 고려할 때 주택의 공정 시장 가치를 추정하는 것이 좋습니다.판매 가격인 라벨은 수치입니다.레이블이 임의의 숫자 값을 취하는 경우 이를 *회귀* 문제라고 합니다.우리의 목표는 예측이 실제 라벨 값에 근접한 모델을 생성하는 것입니다.

많은 실제 문제는 잘 설명 된 회귀 문제입니다.사용자가 영화에 할당할 등급을 예측하는 것은 회귀 문제로 생각할 수 있으며 2009년에 이 위업을 달성하기 위해 훌륭한 알고리즘을 설계했다면 [1-million-dollar Netflix prize](https://en.wikipedia.org/wiki/Netflix_Prize)를 획득했을 수 있습니다.병원에서 환자의 체류 기간을 예측하는 것도 회귀 문제입니다.좋은 경험 법칙은*얼마나됩니까?* 또는*몇 개입니까?* 문제는 다음과 같은 회귀를 제안해야 합니다.

* 이 수술에는 몇 시간이 걸립니까?
* 앞으로 6시간 동안 이 마을의 강우량은 얼마나 될까요?

이전에 머신 러닝으로 작업한 적이 없더라도 회귀 문제를 비공식적으로 해결했을 것입니다.예를 들어 배수구를 수리하고 계약자가 하수관에서 덩어리를 제거하는 데 3시간을 소비했다고 상상해보십시오.그런 다음 350 달러의 청구서를 보냈습니다.이제 친구가 같은 계약자를 2 시간 동안 고용했고 250 달러의 청구서를 받았다고 상상해보십시오.그런 다음 누군가가 다가오는 대량 제거 송장에 대해 얼마나 기대해야하는지 물으면 더 많은 근무 시간이 더 많은 비용이 드는 것과 같은 합리적인 가정을 할 수 있습니다.또한 일부 기본 요금이 있고 계약자가 시간당 요금을 청구한다고 가정 할 수도 있습니다.이러한 가정이 사실이라면, 이 두 가지 데이터 예를 고려할 때 계약자의 가격 구조를 이미 파악할 수 있습니다. 시간당 100 달러와 집에 50 달러가 추가됩니다.그렇게 많이 따랐다면 선형 회귀 뒤에 숨겨진 높은 수준의 아이디어를 이미 이해하게 될 것입니다.

이 경우 계약자의 가격과 정확히 일치하는 매개 변수를 생성 할 수 있습니다.예를 들어 일부 분산이 두 가지 특징 외에 몇 가지 요인으로 인해 발생하는 경우가 있습니다.이 경우 예측과 관측값 사이의 거리를 최소화하는 모델을 학습하려고 노력할 것입니다.대부분의 장에서는 제곱 오류 손실 함수를 최소화하는 데 중점을 둘 것입니다.나중에 볼 수 있듯이이 손실은 가우스 잡음에 의해 데이터가 손상되었다는 가정에 해당합니다.

#### 분류

회귀 모델은 문제를 해결하는 데 적합하지만*몇 개입니까?* 질문, 많은 문제가이 템플릿에 편안하게 구부러지지 않습니다.예를 들어 은행에서 모바일 앱에 수표 스캔을 추가하려고 합니다.여기에는 고객이 스마트폰 카메라로 수표 사진을 찍고 앱이 이미지에 표시된 텍스트를 자동으로 이해할 수 있어야 합니다.특히 손으로 쓴 문자를 알려진 문자 중 하나에 매핑하는 것과 같이 손으로 쓴 텍스트를 훨씬 더 강력하게 이해해야 합니다.이런 종류의*어느 것?* 문제를*분류*라고 합니다.많은 기술이 적용되지만 회귀에 사용되는 알고리즘과는 다른 알고리즘 세트로 처리됩니다.

*분류*에서는 모델이 특징 (예: 이미지의 픽셀 값) 을 살펴본 다음 일부 개별 옵션 세트 중에서 예제가 속하는*카테고리* (공식적으로*클래스*라고 함) 를 예측하기를 원합니다.손으로 쓴 숫자의 경우 0에서 9까지의 숫자에 해당하는 10개의 클래스가 있을 수 있습니다.분류의 가장 간단한 형태는 클래스가 두 개뿐일 때, 우리는*이진 분류*라고 부르는 문제입니다.예를 들어 데이터셋은 동물 이미지로 구성될 수 있으며 레이블은 $\mathrm{\{cat, dog\}}$ 클래스일 수 있습니다.회귀 분석에서는 숫자 값을 출력하기 위해 회귀 변수를 찾았지만 분류에서는 출력값이 예측 된 클래스 할당인 분류기를 찾습니다.

책이 더 기술적이됨에 따라 다루게 될 이유 때문에 어려운 범주형 할당 (예: “고양이” 또는 “개”) 만 출력할 수 있는 모델을 최적화하기가 어려울 수 있습니다.이 경우 일반적으로 확률 언어로 모델을 표현하는 것이 훨씬 쉽습니다.예제의 특징을 감안할 때 모델은 가능한 각 클래스에 확률을 할당합니다.클래스가 $\mathrm{\{cat, dog\}}$인 동물 분류 예제로 돌아가면 분류기가 이미지를 보고 영상이 고양이일 확률을 0.9로 출력할 수 있습니다.이 숫자는 분류자가 이미지가 고양이를 묘사한다고 90\% 확신한다고 말함으로써 해석할 수 있습니다.예측된 클래스에 대한 확률의 크기는 불확실성에 대한 한 가지 개념을 전달합니다.이것이 불확실성에 대한 유일한 개념은 아니며 더 고급 장에서 다른 사람들에 대해 논의 할 것입니다.

가능한 클래스가 두 개 이상인 경우 문제를*다중 클래스 분류*라고 부릅니다.일반적인 예로는 손으로 쓴 문자 인식 $\mathrm{\{0, 1, 2, ... 9, a, b, c, ...\}}$가 있습니다.제곱 오류 손실 함수를 최소화하려고 시도하여 회귀 문제를 공격했지만 분류 문제에 대한 공통 손실 함수는*cross-entropy*라고 하며, 그 이름은 다음 장의 정보 이론에 대한 소개를 통해 이해할 수 있습니다.

가장 가능성이 높은 클래스가 반드시 결정에 사용할 클래스가 아닐 수도 있습니다.:numref:`fig_death_cap`와 같이 뒷마당에서 아름다운 버섯을 발견했다고 가정하십시오.

![Death cap---do not eat!](../img/death-cap.jpg)
:width:`200px`
:label:`fig_death_cap`

이제 분류기를 만들고 사진을 기반으로 버섯이 유독한지 예측하도록 훈련했다고 가정합니다.독극물 검출 분류기가 :numref:`fig_death_cap`에 사망 상한이 포함될 확률이 0.2라고 출력한다고 가정해 보겠습니다.즉, 분류자는 버섯이 데스 캡이 아님을 80\% 확신합니다.그래도 먹으려면 바보가 되어야 할 것입니다.맛있는 저녁 식사의 특정 이점은 죽을 위험이 20\% 에 달하지 않기 때문입니다.즉, 불확실한 위험의 영향이 훨씬 이익보다 큽니다.따라서 손실 함수로 발생할 것으로 예상되는 위험을 계산해야합니다. 즉, 결과의 확률에 이와 관련된 이익 (또는 피해) 을 곱해야합니다.이 경우 버섯을 먹음으로써 발생하는 손실은 $0.2 \times \infty + 0.8 \times 0 = \infty$이 될 수 있지만 폐기 손실은 $0.2 \times 0 + 0.8 \times 1 = 0.8$입니다.우리의주의는 정당화되었습니다. 어떤 균류 학자가 우리에게 말했듯이 :numref:`fig_death_cap`의 버섯은 실제로 죽음의 모자입니다.

분류는 이진, 다중 클래스 또는 다중 레이블 분류보다 훨씬 더 복잡해질 수 있습니다.예를 들어 계층 구조를 다루기 위한 분류에는 몇 가지 변형이 있습니다.계층 구조에서는 여러 클래스 간에 일부 관계가 존재한다고 가정합니다.따라서 모든 오류가 동일한 것은 아닙니다. 오류를 범해야 한다면 멀리 떨어진 클래스가 아닌 관련 클래스로 잘못 분류하는 것이 좋습니다.일반적으로*계층적 분류*라고 합니다.초기 사례 중 하나는 계층 구조로 동물을 조직한 [Linnaeus](https://en.wikipedia.org/wiki/Carl_Linnaeus) 때문입니다.

동물 분류의 경우 푸들 (개 품종) 을 슈나우저 (다른 개 품종) 로 착각하는 것은 그리 나쁘지 않을 수 있지만 푸들을 공룡과 혼동하면 우리 모델은 막대한 벌금을 지불 할 것입니다.관련된 계층 구조는 모델 사용 계획에 따라 달라질 수 있습니다.예를 들어, 딸랑이 뱀과 가터 뱀은 계통 발생 나무에 가까울 수 있지만 덜컹 거리는 소리를 가터로 착각하는 것은 치명적일 수 있습니다.

#### 태깅

일부 분류 문제는 이진 또는 다중 클래스 분류 설정에 잘 맞습니다.예를 들어 고양이와 개를 구별하도록 정규 이진 분류기를 훈련시킬 수 있습니다.컴퓨터 비전의 현재 상태를 고려할 때 기성품 도구를 사용하여 쉽게 이 작업을 수행할 수 있습니다.그럼에도 불구하고 모델이 아무리 정확하더라도 분류자가 :numref:`fig_stackedanimals`에서 네 마리의 동물이 등장하는 독일의 인기 동화 인 브레멘의 타운 뮤지션*의 이미지를 만나면 문제가 발생할 수 있습니다.

![A donkey, a dog, a cat, and a rooster.](../img/stackedanimals.png)
:width:`300px`
:label:`fig_stackedanimals`

보시다시피 :numref:`fig_stackedanimals`에는 고양이가 있고 수탉, 개, 당나귀가 있으며 배경에 나무가 몇 개 있습니다.궁극적으로 모델로 무엇을 하고 싶은지에 따라 이를 이진 분류 문제로 취급하는 것은 그다지 의미가 없을 수 있습니다.대신 이미지에 고양이, 개, 당나귀를 묘사한다고 말할 수 있는 옵션을 모델에 제공할 수 있습니다.
*그리고* 수탉.

상호 배타적이지 않은 클래스를 예측하는 방법을 학습하는 문제를*다중 레이블 분류*라고 합니다.자동 태그 지정 문제는 일반적으로 다중 레이블 분류 문제로 가장 잘 설명됩니다.사람들이 기술 블로그의 게시물에 적용할 수 있는 태그 (예: “기계 학습”, “기술”, “가젯”, “프로그래밍 언어”, “Linux”, “클라우드 컴퓨팅”, “AWS”) 를 생각해 보십시오.이러한 개념은 서로 연관되어 있으므로 일반적인 문서에는 5~10개의 태그가 적용될 수 있습니다.“클라우드 컴퓨팅”에 대한 게시물은 “AWS”를 언급 할 가능성이 높으며 “기계 학습”에 대한 게시물도 “프로그래밍 언어”를 다룰 수 있습니다.

우리는 또한 생물 의학 문헌을 다룰 때 이러한 종류의 문제를 다루어야합니다. 연구자가 문헌에 대한 철저한 검토를 할 수 있기 때문에 기사에 올바르게 태그를 지정하는 것이 중요합니다.국립 의학 도서관에서는 많은 전문 주석가가 PubMed에서 색인화 된 각 기사를 살펴보고 약 28000 개의 태그 모음 인 MeSH의 관련 용어와 연결합니다.이는 시간이 많이 소요되는 프로세스이며 주석 작성자는 일반적으로 아카이빙과 태그 지정 사이에 1년의 지연이 있습니다.기계 학습은 각 논문에 적절한 수동 검토가 있을 때까지 임시 태그를 제공하는 데 사용할 수 있습니다.실제로 몇 년 동안 BioASQ 조직은 이를 정확하게 수행하기 위해 [hosted competitions](http://bioasq.org/)를 보유하고 있습니다.

#### 검색

때로는 각 예제를 버킷이나 실제 값에 할당하고 싶지 않을 때가 있습니다.정보 검색 분야에서는 일련의 항목에 순위를 부여하려고 합니다.웹 검색을 예로 들어 보겠습니다.목표는 특정 페이지가 쿼리와 관련이 있는지 여부를 결정하는 것이 아니라 과다한 검색 결과 중 특정 사용자에게 가장 관련성이 높은 페이지를 결정하는 것입니다.우리는 관련 검색 결과의 순서에 정말 관심이 있으며 학습 알고리즘은 더 큰 집합에서 정렬된 요소 하위 집합을 생성해야 합니다.즉, 알파벳에서 처음 5 글자를 생성하라는 요청을 받으면 “A B C D E”와 “C A B E D”를 반환하는 것 사이에 차이가 있습니다.결과 집합이 같더라도 집합 내의 순서가 중요합니다.

이 문제에 대한 한 가지 가능한 해결책은 먼저 세트의 모든 요소에 해당 관련성 점수를 할당 한 다음 최고 등급 요소를 검색하는 것입니다. [PageRank](https://en.wikipedia.org/wiki/PageRank), Google 검색 엔진의 원래 비밀 소스는 이러한 채점 시스템의 초기 예 였지만 그랬다는 점에서 특이했습니다.실제 쿼리에 의존하지 않습니다.여기서는 간단한 관련성 필터를 사용하여 관련 항목 집합을 식별한 다음 PageRank에서 쿼리 용어가 포함된 결과를 정렬했습니다.오늘날 검색 엔진은 기계 학습 및 행동 모델을 사용하여 쿼리 종속 관련성 점수를 얻습니다.이 주제에 관한 전체 학술 회의가 있습니다.

#### 추천인 시스템
:label:`subsec_recommender_systems`

추천 시스템은 검색 및 순위 지정과 관련된 또 다른 문제 설정입니다.관련 항목 집합을 사용자에게 표시하는 것이 목표인 경우 문제는 비슷합니다.가장 큰 차이점은 강조점입니다.
*개인화*
추천자 시스템의 맥락에서 특정 사용자에게예를 들어 영화 추천의 경우 공상 과학 팬의 결과 페이지와 Peter Sellers의 코미디 감정가의 결과 페이지가 크게 다를 수 있습니다.소매 제품, 음악 및 뉴스 추천과 같은 다른 추천 설정에서도 비슷한 문제가 나타납니다.

경우에 따라 고객은 특정 상품을 얼마나 좋아했는지에 대한 명시적인 피드백 (예: Amazon, IMDb 및 Goodreads의 상품 평점 및 리뷰) 을 제공합니다.다른 경우에는 재생 목록에서 제목을 건너뛰는 등 암시적인 피드백을 제공합니다. 이는 불만족을 나타낼 수 있지만 곡이 문맥상 부적절하다는 것을 나타낼 수 있습니다.가장 간단한 공식에서 이러한 시스템은 사용자와 항목이 주어지면 추정 등급 또는 구매 확률과 같은 일부 점수를 추정하도록 훈련됩니다.

이러한 모델이 주어지면 특정 사용자에 대해 점수가 가장 큰 객체 집합을 검색할 수 있으며, 이 객체 집합을 사용자에게 추천할 수 있습니다.생산 시스템은 훨씬 더 발전되었으며 이러한 점수를 계산할 때 자세한 사용자 활동 및 항목 특성을 고려합니다. :numref:`fig_deeplearning_amazon`는 선호도를 캡처하도록 조정 된 개인화 알고리즘을 기반으로 Amazon에서 권장하는 딥 러닝 서적의 예입니다.

![Deep learning books recommended by Amazon.](../img/deeplearning-amazon.jpg)
:label:`fig_deeplearning_amazon`

엄청난 경제적 가치에도 불구하고 예측 모델 위에 순진하게 구축된 추천 시스템은 심각한 개념적 결함을 겪고 있습니다.우선, *검열된 피드백*만 관찰합니다. 사용자는 자신이 강하게 느끼는 영화를 우선적으로 평가합니다.예를 들어, 5점 척도에서 항목에 별 5개 및 1개 등급이 많이 부여되지만 별 3개 등급은 눈에 띄게 적다는 것을 알 수 있습니다.또한 현재 구매 습관은 현재 시행중인 추천 알고리즘의 결과이지만 학습 알고리즘이 항상 이러한 세부 사항을 고려하지는 않습니다.따라서 추천자 시스템이 우선적으로 항목을 푸시한 다음 (더 많은 구매로 인해) 더 나은 항목을 가져와 더 자주 추천하는 피드백 루프가 형성 될 수 있습니다.검열, 인센티브 및 피드백 루프를 처리하는 방법에 대한 이러한 문제 중 상당수는 중요한 공개 연구 질문입니다.

#### 시퀀스 학습

지금까지 일부 고정 된 수의 입력이 있고 고정 된 수의 출력을 생성하는 문제를 살펴 보았습니다.예를 들어 평방 피트, 침실 수, 욕실 수, 시내까지의 도보 시간 등 고정 된 기능 세트에서 주택 가격을 예측하는 것을 고려했습니다.또한 고정 차원의 이미지에서 고정 된 수의 클래스 각각에 속할 예측 확률로 매핑하거나 사용자 ID와 제품 ID를 가져와 별 등급을 예측하는 방법에 대해서도 논의했습니다.이 경우 고정 길이 입력을 모델에 공급하여 출력을 생성하면 모델은 방금 본 내용을 즉시 잊어 버립니다.

입력이 실제로 모두 동일한 차원을 가지고 있고 연속적인 입력이 실제로 서로 관련이 없다면 괜찮을 수 있습니다.하지만 비디오 스니펫은 어떻게 처리할까요?이 경우 각 스니펫은 서로 다른 수의 프레임으로 구성될 수 있습니다.이전 프레임이나 후속 프레임을 고려하면 각 프레임에서 어떤 일이 벌어지고 있는지 추측하는 것이 훨씬 더 강할 수 있습니다.언어도 마찬가지입니다.딥러닝의 인기 있는 문제 중 하나는 기계 번역입니다. 즉, 일부 소스 언어로 문장을 수집하고 다른 언어로 번역을 예측하는 작업입니다.

이러한 문제는 의학에서도 발생합니다.중환자 실의 환자를 모니터링하고 향후 24시간 동안의 사망 위험이 일부 임계값을 초과하는 경우 경보를 발령하는 모델을 원할 수 있습니다.우리는이 모델이 매시간 환자 병력에 대해 알고있는 모든 것을 버리고 가장 최근의 측정을 기반으로 예측하는 것을 원하지 않을 것입니다.

이러한 문제는 기계 학습의 가장 흥미로운 응용 분야 중 하나이며*시퀀스 학습*의 사례입니다.입력 시퀀스를 수집하거나 출력 시퀀스를 내보내는 모델 (또는 둘 다) 이 필요합니다.구체적으로,
*시퀀스 대 시퀀스 학습* 문제 고려
여기서 입력과 출력은 기계 번역 및 음성 음성의 텍스트 전사와 같은 가변 길이 시퀀스입니다.모든 유형의 시퀀스 변환을 고려하는 것은 불가능하지만 다음과 같은 특별한 경우를 언급 할 가치가 있습니다.

**태그 지정 및 구문 분석**.여기에는 텍스트 시퀀스에 속성으로 주석을 다는 작업이 포함됩니다.
즉, 입력과 출력의 수는 본질적으로 동일합니다.예를 들어 동사와 주어가 어디에 있는지 알고 싶을 수 있습니다.또는 어떤 단어가 명명된 엔티티인지 알고 싶을 수도 있습니다.일반적으로 목표는 구조적 및 문법적 가정에 따라 텍스트를 분해하고 주석을 추가하여 주석을 얻는 것입니다.실제보다 더 복잡하게 들립니다.아래는 어떤 단어가 명명된 엔터티 (“Ent”로 태그) 를 참조하는지 나타내는 태그로 문장에 주석을 다는 아주 간단한 예입니다.

```text
Tom has dinner in Washington with Sally
Ent  -    -    -     Ent      -    Ent
```

**자동 음성 인식**.음성 인식을 사용하면 입력 시퀀스가
스피커의 오디오 녹음 (:numref:`fig_speech`에 표시) 이며 출력은 화자가 말한 내용의 텍스트 사본입니다.문제는 텍스트보다 더 많은 오디오 프레임 (사운드는 일반적으로 8kHz 또는 16kHz로 샘플링 됨) 이 있다는 것입니다. 즉, 수천 개의 샘플이 단일 구어에 해당 할 수 있기 때문에 오디오와 텍스트 사이에 1:1 대응이 없습니다.이는 출력이 입력값보다 훨씬 짧은 시퀀스-투-시퀀스 학습 문제입니다.

![`-D-e-e-p- L-ea-r-ni-ng-` in an audio recording.](../img/speech.png)
:width:`700px`
:label:`fig_speech`

**텍스트 음성 변환**.이것은 자동 음성 인식의 반대입니다.
즉, 입력은 텍스트이고 출력은 오디오 파일입니다.이 경우 출력이 입력보다 훨씬 깁니다.사람이 나쁜 오디오 파일을 인식하기는 쉽지만 컴퓨터에서는 그렇게 사소한 일이 아닙니다.

**기계 번역**.음성 인식의 경우와 달리 해당하는 경우
입력과 출력은 동일한 순서 (정렬 후) 로 발생하며, 기계 번역에서는 주문 반전이 중요 할 수 있습니다.즉, 한 시퀀스를 다른 시퀀스로 변환하는 동안 입력 및 출력 수나 해당 데이터 예제의 순서는 동일하지 않다고 가정합니다.독일인이 문장 끝에 동사를 배치하는 특이한 경향에 대한 다음 예시를 고려하십시오.

```text
German:           Haben Sie sich schon dieses grossartige Lehrwerk angeschaut?
English:          Did you already check out this excellent tutorial?
Wrong alignment:  Did you yourself already this excellent tutorial looked-at?
```

다른 학습 과제에는 많은 관련 문제가 나타납니다.예를 들어 사용자가 웹 페이지를 읽는 순서를 결정하는 것은 2차원 레이아웃 분석 문제입니다.대화 문제는 모든 종류의 추가 합병증을 나타내며, 다음에 무엇을 말할지 결정하려면 실제 지식과 긴 시간적 거리에 걸친 대화의 이전 상태를 고려해야합니다.이들은 활발한 연구 분야입니다.

### 비지도 및 자가 지도 학습

지금까지의 모든 예는 지도 학습, 즉 특징과 해당 레이블 값을 모두 포함하는 거대한 데이터 세트를 모델에 제공하는 상황과 관련이 있습니다.감독 학습자는 매우 전문화 된 직업과 극도로 진부한 상사를 가지고 있다고 생각할 수 있습니다.사장님은 어깨 너머로 서서 상황에서 행동으로 매핑하는 법을 배울 때까지 모든 상황에서해야 할 일을 정확히 알려줍니다.그런 상사를 위해 일하는 것은 꽤 절름발이 들린다.반면에이 상사를 기쁘게하는 것은 쉽습니다.패턴을 최대한 빨리 인식하고 행동을 모방합니다.

완전히 반대되는 방식으로, 자신이 무엇을하고 싶은지 전혀 모르는 상사를 위해 일하는 것은 실망 스러울 수 있습니다.그러나 데이터 과학자가 될 계획이라면 익숙해지는 것이 좋습니다.상사는 거대한 데이터 덤프를 건네주고 데이터 과학을 수행하라고 말할 수 있습니다!* 그렇기 때문에 모호하게 들립니다.우리는 이러한 종류의 문제를 '감독되지 않은 학습'이라고 부르며, 우리가 할 수 있는 질문의 유형과 수는 창의성에 의해서만 제한됩니다.우리는 다음 장에서 자율 학습 기술을 다룰 것입니다.지금은 식욕을 자극하기 위해 다음 질문 중 몇 가지를 설명합니다.

* 적은 수의 프로토타입을 찾을 수 있을까요?
데이터를 정확하게 요약할 수 있을까요?사진 세트가 주어지면 풍경 사진, 개, 아기, 고양이, 산봉우리 사진으로 그룹화할 수 있습니까?마찬가지로 사용자의 탐색 활동 모음이 주어지면 유사한 행동을 가진 사용자로 그룹화할 수 있습니까?이 문제를 일반적으로*클러스터링*이라고 합니다.
* 적은 수의 매개 변수를 찾을 수 있습니까?
데이터의 관련 속성을 정확하게 캡처합니까?공의 궤적은 공의 속도, 직경 및 질량으로 잘 설명됩니다.재단사는 옷을 입을 목적으로 인체 모양을 상당히 정확하게 설명하는 소수의 매개 변수를 개발했습니다.이러한 문제를*부분공간 추정*이라고 합니다.종속성이 선형인 경우*주성분 분석*이라고 합니다.
* (임의로 구조화된) 객체의 표현이 있는가?
유클리드 공간에서 상징적 속성이 잘 일치 할 수 있습니까?이는 “로마” $-$ “이탈리아” $+$ “프랑스” $=$ “파리”와 같은 엔티티와 엔티티의 관계를 설명하는 데 사용할 수 있습니다.
* 근본 원인에 대한 설명이 있습니까?
우리가 관찰하는 많은 데이터들?예를 들어, 주택 가격, 오염, 범죄, 위치, 교육 및 급여에 대한 인구 통계 데이터가 있다면 경험적 데이터를 기반으로 어떻게 관련되어 있는지 알 수 있습니까?*인과 관계* 및*확률적 그래픽 모델*과 관련된 필드는 이 문제를 해결합니다.
* 자율 학습의 또 다른 중요하고 흥미로운 최근 개발
*생성적 적대 네트워크*의 출현입니다.이를 통해 이미지 및 오디오와 같은 복잡한 구조화된 데이터까지 데이터를 합성할 수 있는 절차적 방법을 제공합니다.기본 통계 메커니즘은 실제 데이터와 가짜 데이터가 동일한지 확인하는 테스트입니다.

비지도 학습의 한 형태로서,
*자가 지도 학습*
는 레이블이 지정되지 않은 데이터를 활용하여 다른 부분을 사용하여 데이터의 일부 보류된 부분을 예측하는 등 교육 감독을 제공합니다.텍스트의 경우 라벨링 작업 없이 큰 상체에서 주변 단어 (컨텍스트) 를 사용하여 무작위로 마스크된 단어를 예측하여 “공백을 채우도록”모델을 훈련시킬 수 있습니다. :cite:`Devlin.Chang.Lee.ea.2018`!이미지의 경우 동일한 이미지 :cite:`Doersch.Gupta.Efros.2015`에서 잘린 두 영역 사이의 상대적 위치를 알려주도록 모델을 훈련시킬 수 있습니다.자율 학습의 이 두 가지 예에서 가능한 단어와 상대 위치를 예측하는 훈련 모델은 모두 분류 작업입니다 (지도 학습에서).

### 환경과의 상호 작용

지금까지 데이터가 실제로 어디서 왔는지 또는 기계 학습 모델이 출력을 생성할 때 실제로 어떤 일이 발생하는지에 대해서는 논의하지 않았습니다.감독 학습과 비지도 학습은 이러한 문제를 매우 정교한 방식으로 해결하지 못하기 때문입니다.두 경우 모두 대량의 데이터를 미리 파악한 다음 환경과 다시 상호 작용하지 않고 패턴 인식 기계를 작동시킵니다.알고리즘이 환경과 연결이 끊어진 후에 모든 학습이 이루어지기 때문에*오프라인 학습*이라고도 합니다.지도 학습의 경우 환경에서의 데이터 수집을 고려한 프로세스는 :numref:`fig_data_collection`와 같습니다.

![Collecting data for supervised learning from an environment.](../img/data-collection.svg)
:label:`fig_data_collection`

이러한 오프라인 학습의 단순함에는 매력이 있습니다.장점은 이러한 다른 문제로부터 방해받지 않고 패턴 인식에 대해 단독으로 걱정할 수 있다는 것입니다.그러나 단점은 문제 공식화가 상당히 제한적이라는 것입니다.더 야심적이거나 Asimov의 로봇 시리즈를 읽으면서 자랐다면 예측을 할 수있을뿐만 아니라 세계에서 행동을 취할 수있는 인위적으로 지능적인 봇을 상상할 수 있습니다.우리는 예측 모델뿐만 아니라 지능형*에이전트*에 대해 생각하고 싶습니다.즉, 예측만 하는 것이 아니라*행동*을 선택하는 것에 대해 생각해야 합니다.또한 예측과 달리 행동은 실제로 환경에 영향을 미칩니다.지능형 에이전트를 교육하려면 해당 작업이 에이전트의 향후 관찰에 영향을 미칠 수 있는 방식을 고려해야 합니다.

환경과의 상호 작용을 고려하면 새로운 모델링 질문이 생깁니다.다음은 몇 가지 예일뿐입니다.

* 환경은 우리가 이전에 한 일을 기억합니까?
* 환경이 우리를 돕고 싶습니까? 예를 들어 사용자가 음성 인식기로 텍스트를 읽는 경우?
* 환경이 우리를 이기고 싶습니까? 즉, 스팸 필터링 (스패머에 대한) 또는 게임 플레이 (상대방 대비) 와 같은 적대적인 설정입니까?
* 환경이 신경 쓰지 않습니까?
* 환경에 변화하는 역학이 있습니까?예를 들어, 미래 데이터는 항상 과거와 비슷합니까, 아니면 시간이 지남에 따라 패턴이 자연스럽게 또는 자동화된 도구에 반응하여 변합니까?

이 마지막 질문은 훈련 데이터와 검정 데이터가 다를 때*분포 이동* 문제를 제기합니다.강사가 작성한 시험을 볼 때 우리 대부분이 경험 한 문제이며 숙제는 조교가 작성했습니다.다음으로 환경과의 상호 작용을 명시적으로 고려하는 설정인 강화 학습에 대해 간략하게 설명하겠습니다.

### 강화 학습

머신 러닝을 사용하여 환경과 상호 작용하고 조치를 취하는 에이전트를 개발하는 데 관심이 있다면*강화 학습*에 초점을 맞출 것입니다.여기에는 로봇 공학, 대화 시스템, 비디오 게임용 인공 지능 (AI) 개발에 대한 응용 프로그램이 포함될 수 있습니다.
*심층 강화 학습*, 적용
강화 학습 문제에 대한 딥 러닝이 인기가 급증했습니다.시각적 입력만으로 아타리 게임에서 인간을 이길 수있는 획기적인 심층 Q 네트워크와 보드 게임 Go에서 세계 챔피언을 무너 뜨린 AlphaGo 프로그램이 두 가지 두드러진 예입니다.

강화 학습은 에이전트가 일련의 시간 단계에 걸쳐 환경과 상호 작용하는 문제에 대한 매우 일반적인 설명을 제공합니다.각 시간 스텝에서 에이전트는 환경으로부터*관찰*을 받고 이후에 일부 메커니즘 (액추에이터라고도 함) 을 통해 환경으로 다시 전송되는*작업*을 선택해야 합니다.마지막으로 에이전트는 환경으로부터 보상을 받습니다.이 프로세스는 :numref:`fig_rl-environment`에 설명되어 있습니다.그런 다음 에이전트는 후속 관찰을 받고 후속 작업을 선택하는 식으로 계속됩니다.강화 학습 에이전트의 행동은 정책에 의해 관리됩니다.간단히 말해, *정책*은 환경 관찰에서 행동으로 매핑하는 함수일 뿐입니다.강화 학습의 목표는 좋은 정책을 수립하는 것입니다.

![The interaction between reinforcement learning and an environment.](../img/rl-environment.svg)
:label:`fig_rl-environment`

강화 학습 프레임 워크의 일반성을 과장하기는 어렵습니다.예를 들어, 지도 학습 문제를 강화 학습 문제로 던질 수 있습니다.분류 문제가 있다고 가정해 보겠습니다.각 클래스에 해당하는 하나의 작업으로 강화 학습 에이전트를 만들 수 있습니다.그런 다음 원래 지도 학습 문제의 손실 함수와 정확히 동일한 보상을 제공하는 환경을 만들 수 있습니다.

즉, 강화 학습은 지도 학습이 할 수 없는 많은 문제를 해결할 수도 있습니다.예를 들어 지도 학습에서는 항상 훈련 입력이 올바른 레이블과 연관되어 있을 것으로 예상합니다.그러나 강화 학습에서는 각 관찰에 대해 환경이 최적의 조치를 취한다고 가정하지 않습니다.일반적으로 약간의 보상만 받습니다.더욱이 환경은 어떤 행동이 보상으로 이어졌는지 알려주지 못할 수도 있습니다.

예를 들어 체스 게임을 생각해보십시오.유일한 실제 보상 신호는 게임이 끝날 때, 우리가 이길 때, 보상을 1로 할당하거나 패배했을 때 -1의 보상을 할당 할 수 있습니다.따라서 강화 학습자는*학점 할당* 문제, 즉 결과에 대해 신용하거나 비난할 행동을 결정해야 합니다.10월 11일에 승진을 받는 직원도 마찬가지입니다.이 프로모션은 전년도에 잘 선택된 많은 조치를 반영할 가능성이 높습니다.앞으로 더 많은 프로모션을 받으려면 그 과정에서 어떤 행동이 프로모션으로 이어졌는지 파악해야 합니다.

강화 학습자는 부분적 관찰 가능성 문제를 다루어야 할 수도 있습니다.즉, 현재 관측치가 현재 상태에 대한 모든 것을 알려주지 못할 수도 있습니다.청소 로봇이 집안의 많은 동일한 옷장 중 하나에 갇혀 있다고 가정 해보십시오.로봇의 정확한 위치 (따라서 상태) 를 추론하려면 옷장에 들어가기 전에 이전 관찰을 고려해야 할 수 있습니다.

마지막으로, 어느 시점에서든 강화 학습자는 한 가지 좋은 정책을 알 수 있지만 에이전트가 시도한 적이없는 다른 더 나은 정책이 많을 수 있습니다.강화 학습자는 현재 가장 잘 알려진 전략을 정책으로* 활용'할지 또는 전략 공간을* 탐색'할지 여부를 지속적으로 선택하여 지식에 대한 대가로 단기 보상을 포기할 수 있습니다.

일반적인 강화 학습 문제는 매우 일반적인 환경입니다.조치는 후속 관찰에 영향을 미칩니다.보상은 선택한 행동에 해당하는 경우에만 관찰됩니다.환경이 완전히 또는 부분적으로 관찰될 수 있습니다.이 모든 복잡성을 한 번에 설명하면 너무 많은 연구자에게 필요할 수 있습니다.더욱이 모든 실질적인 문제가 이러한 모든 복잡성을 나타내는 것은 아닙니다.그 결과 연구자들은 강화 학습 문제의 여러 가지 특별한 사례를 연구했습니다.

환경이 완전히 관찰되면 강화 학습 문제를*마르코프 의사 결정 과정*이라고 합니다.국가가 이전 조치에 의존하지 않는 경우 문제를*상황에 맞는 산적 문제*라고 부릅니다.상태가 없을 때, 처음에 알려지지 않은 보상으로 사용 가능한 일련의 행동 만있는 경우, 이 문제는 고전적인*다중 무장 산적 문제*입니다.

## 루츠

머신 러닝이 해결할 수 있는 몇 가지 문제를 방금 검토했습니다.딥 러닝은 다양한 머신 러닝 문제를 해결하기 위한 강력한 도구를 제공합니다.많은 딥 러닝 방법이 최근 발명품이지만, 데이터 및 신경망 (많은 딥 러닝 모델의 이름) 을 사용한 프로그래밍의 핵심 아이디어는 수세기 동안 연구되어 왔습니다.실제로 인간은 오랫동안 데이터를 분석하고 미래의 결과를 예측하려는 욕구를 가지고 있으며 많은 자연 과학이 이에 뿌리를두고 있습니다.예를 들어, 베르누이 분포는 [야곱 베르누이 (1655-1705)](https://en.wikipedia.org/wiki/Jacob_Bernoulli) 의 이름을 따서 명명되었으며, 가우스 분포는 [칼 프리드리히 가우스 (1777-1855)](https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss) 에 의해 발견되었습니다.예를 들어 그는 보험 계산에서 의료 진단에 이르기까지 수많은 문제에 오늘날에도 여전히 사용되는 최소 평균 제곱 알고리즘을 발명했습니다.이러한 도구는 자연 과학에서 실험적인 접근 방식을 일으켰습니다. 예를 들어 저항의 전류와 전압과 관련된 옴의 법칙은 선형 모델로 완벽하게 설명됩니다.

중세 시대에도 수학자들은 견적에 대한 예리한 직감을 가지고있었습니다.예를 들어, [Jacob Köbel (1460—1533)](https://www.maa.org/press/periodicals/convergence/mathematical-treasures-jacob-kobels-geometry) 의 기하학 책은 평균 발 길이를 얻기 위해 성인 남성 발 16 명의 평균 길이를 보여줍니다.

![Estimating the length of a foot.](../img/koebel.jpg)
:width:`500px`
:label:`fig_koebel`

:numref:`fig_koebel`는 이 추정기의 작동 방식을 보여줍니다.16명의 성인 남성은 교회를 떠날 때 연속으로 줄을 서라는 요청을 받았습니다.그런 다음 총 길이를 16으로 나누어 현재 1 피트에 해당하는 추정치를 얻었습니다.이 “알고리즘”은 나중에 기형적인 발을 처리하기 위해 개선되었습니다. 발이 가장 짧고 가장 긴 두 남자가 각각 파견되어 나머지 부분에 대해서만 평균화되었습니다.이는 절사 평균 추정치의 가장 초기 예 중 하나입니다.

통계는 실제로 데이터 수집 및 가용성과 함께 시작되었습니다.타이탄 중 하나 인 [로널드 피셔 (1890—1962)](https://en.wikipedia.org/wiki/Ronald_Fisher) 는 이론과 유전학에서의 적용에 크게 기여했습니다.그의 알고리즘 (예: 선형 판별 분석) 과 공식 (예: Fisher 정보 행렬) 은 오늘날에도 여전히 자주 사용되고 있습니다.실제로 Fisher가 1936년에 발표한 Iris 데이터 세트조차도 여전히 기계 학습 알고리즘을 설명하는 데 사용됩니다.그는 또한 우생학의 지지자였습니다. 데이터 과학의 도덕적으로 모호한 사용은 산업과 자연 과학에서의 생산적인 사용만큼 길고 지속적인 역사를 가지고 있음을 상기시켜야합니다.

기계 학습의 두 번째 영향은 [클로드 섀넌 (1916-2001)](https://en.wikipedia.org/wiki/Claude_Shannon) 의 정보 이론과 [앨런 튜링 (1912-1954)](https://en.wikipedia.org/wiki/Alan_Turing) 을 통한 계산 이론에서 비롯되었습니다.튜링은 “기계가 생각할 수 있을까?”그의 유명한 논문* 컴퓨팅 기계 및 지능* :cite:`Turing.1950`에서.그가 튜링 테스트라고 설명한 바에 따르면, 인간 평가자가 텍스트 상호 작용을 기반으로 기계의 응답과 사람의 응답을 구별하기 어려운 경우 기계는*지능형*으로 간주 될 수 있습니다.

신경 과학과 심리학에서 또 다른 영향을 찾을 수 있습니다.결국 인간은 분명히 지능적인 행동을 보입니다.따라서 이 역량을 설명하고 리버스 엔지니어링할 수 있는지 여부를 묻는 것이 합리적입니다.이러한 방식으로 영감을 얻은 가장 오래된 알고리즘 중 하나는 [도널드 헵브 (1904~1985)](https://en.wikipedia.org/wiki/Donald_O._Hebb) 에 의해 공식화되었습니다.그의 획기적인 책*행동 조직* :cite:`Hebb.Hebb.1949`에서 그는 뉴런이 긍정적 강화를 통해 학습한다고 주장했습니다.이것은 Hebbian 학습 규칙으로 알려졌습니다.Rosenblatt의 퍼셉트론 학습 알고리즘의 프로토 타입이며 오늘날 딥 러닝을 뒷받침하는 많은 확률 적 경사 하강 알고리즘의 토대를 마련했습니다. 원하는 동작을 강화하고 바람직하지 않은 동작을 줄여 신경망에서 매개 변수의 올바른 설정을 얻습니다.

생물학적 영감은*신경망*의 이름을 부여한 것입니다.한 세기 이상 (1873 년 알렉산더 베인과 1890 년 제임스 셰링턴의 모델로 거슬러 올라가는) 연구자들은 상호 작용하는 뉴런 네트워크와 유사한 계산 회로를 조립하려고 시도했습니다.시간이 지남에 따라 생물학의 해석은 문자 그대로가 줄어들었지만 이름은 붙어 있습니다.그 중심에는 오늘날 대부분의 네트워크에서 찾을 수 있는 몇 가지 핵심 원칙이 있습니다.

* 선형 및 비선형 처리 장치의 교대이며, 종종*레이어*라고 합니다.
* 전체 네트워크의 매개변수를 한 번에 조정하기 위해 체인 규칙 (*역전파*이라고도 함) 을 사용합니다.

초기의 급속한 발전 이후 신경망에 대한 연구는 1995년경부터 2005년까지 쇠퇴했습니다.이는 주로 두 가지 이유 때문이었습니다.첫째, 네트워크를 훈련시키는 것은 계산 비용이 매우 많이 듭니다.지난 세기 말에는 랜덤 액세스 메모리가 많았지만 계산 능력은 부족했습니다.둘째, 데이터 세트는 상대적으로 작았습니다.실제로 1932년 피셔의 아이리스 데이터셋은 알고리즘의 효능을 테스트하는 데 널리 사용되는 도구였습니다.60000개의 손으로 쓴 숫자가 있는 MNIST 데이터셋은 거대한 것으로 간주되었습니다.

데이터와 계산이 부족하다는 점을 감안할 때 커널 방법, 의사 결정 트리 및 그래픽 모델과 같은 강력한 통계 도구가 경험적으로 우수한 것으로 입증되었습니다.신경망과 달리 훈련하는 데 몇 주가 필요하지 않았으며 강력한 이론적 보장과 함께 예측 가능한 결과를 제공했습니다.

## 딥 러닝으로 가는 길

월드 와이드 웹 (World Wide Web), 수억 명의 사용자에게 온라인으로 서비스를 제공하는 회사의 출현, 저렴한 고품질 센서, 저렴한 데이터 스토리지 (Kryder의 법칙) 및 저렴한 계산 (무어의 법칙), 특히원래 컴퓨터 게임용으로 설계된 GPU의 형태입니다.갑자기 계산적으로 실현 불가능한 것처럼 보이는 알고리즘과 모델이 관련성이 높아졌습니다 (그 반대도 마찬가지입니다).이것은 :numref:`tab_intro_decade`에서 가장 잘 설명되어 있습니다.

:데이터 세트 vs. 컴퓨터 메모리 및 계산 능력

|Decade|Dataset|Memory|Floating point calculations per second|
|:--|:-|:-|:-|
|1970|100 (Iris)|1 KB|100 KF (Intel 8080)|
|1980|1 K (House prices in Boston)|100 KB|1 MF (Intel 80186)|
|1990|10 K (optical character recognition)|10 MB|10 MF (Intel 80486)|
|2000|10 M (web pages)|100 MB|1 GF (Intel Core)|
|2010|10 G (advertising)|1 GB|1 TF (Nvidia C2050)|
|2020|1 T (social network)|100 GB|1 PF (Nvidia DGX-2)|
:label:`tab_intro_decade`

랜덤 액세스 메모리가 데이터 증가에 보조를 맞추지 못했다는 것은 분명합니다.동시에 계산 능력의 증가는 사용 가능한 데이터의 증가를 능가했습니다.즉, 통계 모델은 계산 예산 증가로 인해 이러한 매개 변수를 최적화하는 데 더 많은 시간을 소비하는 동시에 메모리 효율성을 높일 수 있어야 합니다 (일반적으로 비선형성을 추가하여 달성).결과적으로 기계 학습 및 통계의 스위트 스팟은 (일반화 된) 선형 모델과 커널 방법에서 심층 신경망으로 이동했습니다.이것은 또한 다층 퍼셉트론 :cite:`McCulloch.Pitts.1943`, 컨볼 루션 신경망 :cite:`LeCun.Bottou.Bengio.ea.1998`, 장단기 기억 :cite:`Hochreiter.Schmidhuber.1997` 및 Q- 러닝 :cite:`Watkins.Dayan.1992`와 같은 딥 러닝의 많은 주류가 본질적으로 “재발견”된 이유 중 하나입니다.상당한 시간.

통계 모델, 응용 및 알고리즘의 최근 진전은 때때로 종의 진화가 빠르게 진행되는 순간 인 캄브리아기 폭발과 비유되었습니다.실제로 최첨단 기술은 수십 년 된 알고리즘에 적용된 사용 가능한 리소스의 단순한 결과가 아닙니다.아래 목록은 연구자들이 지난 10년 동안 엄청난 발전을 달성하는 데 도움이 된 아이디어의 표면을 거의 긁지 못합니다.

* *드롭아웃* :cite:`Srivastava.Hinton.Krizhevsky.ea.2014`와 같은 새로운 용량 제어 방법은 과적합의 위험을 완화하는 데 도움이 되었습니다.이는 신경망 전체에 노이즈 주입 :cite:`Bishop.1995`를 적용하고 훈련 목적으로 가중치를 랜덤 변수로 대체함으로써 달성되었습니다.
* 주의 메커니즘은 한 세기 넘게 통계를 괴롭혔던 두 번째 문제, 즉 학습 가능한 매개 변수의 수를 늘리지 않고 시스템의 기억력과 복잡성을 높이는 방법을 해결했습니다.연구원들은 학습 가능한 포인터 구조 :cite:`Bahdanau.Cho.Bengio.2014`로만 볼 수 있는 것을 사용하여 우아한 해결책을 찾았습니다.예를 들어 고정 차원 표현에서 기계 번역의 경우 전체 텍스트 시퀀스를 기억할 필요 없이 번역 프로세스의 중간 상태에 대한 포인터만 저장해야 했습니다.이렇게 하면 새 시퀀스 생성을 시작하기 전에 모델이 더 이상 전체 시퀀스를 기억할 필요가 없기 때문에 긴 시퀀스의 정확도가 크게 향상되었습니다.
* 예를 들어, 메모리 네트워크 (:cite:`Sukhbaatar.Weston.Fergus.ea.2015`) 및 신경 프로그래머-인터프리터 (:cite:`Reed.De-Freitas.2015`) 를 통한 다단계 설계는 통계 모델러들이 추론에 대한 반복적인 접근법을 기술할 수 있게 해주었다.이러한 도구를 사용하면 심층 신경망의 내부 상태를 반복적으로 수정할 수 있으므로 프로세서가 계산을 위해 메모리를 수정하는 방법과 유사한 일련의 추론에서 후속 단계를 수행 할 수 있습니다.
* 또 다른 주요 개발은 생성적 적대 네트워크 :cite:`Goodfellow.Pouget-Abadie.Mirza.ea.2014`의 발명이었습니다.전통적으로 밀도 추정 및 생성 모델의 통계적 방법은 적절한 확률 분포와 이로부터 샘플링하기 위한 (종종 근사치) 알고리즘을 찾는 데 중점을 두었습니다.결과적으로 이러한 알고리즘은 통계 모델에 내재된 유연성 부족으로 인해 크게 제한되었습니다.생성적 적대 네트워크의 중요한 혁신은 샘플러를 미분 가능한 파라미터를 가진 임의의 알고리즘으로 대체하는 것이었습니다.그런 다음 판별기 (사실상 2-표본 검정) 가 가짜와 실제 데이터를 구별할 수 없도록 조정됩니다.임의의 알고리즘을 사용하여 데이터를 생성하는 기능을 통해 다양한 기법에 대한 밀도 추정을 가능하게했습니다.질주하는 얼룩말 :cite:`Zhu.Park.Isola.ea.2017`와 가짜 유명인 얼굴 :cite:`Karras.Aila.Laine.ea.2017`의 예는 모두 이러한 진전에 대한 증언입니다.아마추어 낙서라도 장면의 레이아웃이 :cite:`Park.Liu.Wang.ea.2019`과 어떻게 보이는지 설명하는 스케치만으로 사실적인 이미지를 만들 수 있습니다.
* 대부분의 경우 단일 GPU로는 훈련에 사용할 수 있는 많은 양의 데이터를 처리할 수 없습니다.지난 10년 동안 병렬 및 분산 훈련 알고리즘을 구축하는 기능이 크게 향상되었습니다.확장 가능한 알고리즘을 설계할 때 주요 과제 중 하나는 딥 러닝 최적화의 핵심인 확률적 경사 하강법 (Stochastic Gradient Descent) 이 처리할 데이터의 비교적 작은 미니 배치에 의존한다는 것입니다.동시에 작은 배치로 인해 GPU의 효율성이 제한됩니다.따라서 미니배치 크기가 배치당 32개 이미지인 1024개의 GPU에서 훈련하면 약 32000개의 이미지로 구성된 집계 미니배치에 해당합니다.Li :cite:`Li.2017`의 최근 작업과 이후 :cite:`You.Gitman.Ginsburg.2017` 및 :cite:`Jia.Song.He.ea.2018`의 최근 작업은 크기를 최대 64000개의 관측치로 밀어 이미지넷 데이터 세트에서 ResNet-50 모델에 대한 학습 시간을 7분 미만으로 줄였습니다.비교를 위해 초기 훈련 시간은 일 단위로 측정되었습니다.
* 계산을 병렬화하는 능력은 적어도 시뮬레이션이 선택 사항일 때마다 강화 학습의 발전에 매우 결정적인 기여를 했습니다.이로 인해 Go, Atari 게임, 스타크래프트 및 물리 시뮬레이션 (예: MujoCO 사용) 에서 초인적 성능을 달성하는 컴퓨터에서 상당한 발전이 이루어졌습니다.AlphaGo에서 이를 달성하는 방법에 대한 설명은 예를 들어 :cite:`Silver.Huang.Maddison.ea.2016`를 참조하십시오.간단히 말해서, 강화 학습은 많은 (주, 행동, 보상) 트리플을 사용할 수있는 경우, 즉 서로 어떻게 관련되는지 배우기 위해 많은 것을 시도 할 수있을 때마다 가장 잘 작동합니다.시뮬레이션은 이러한 길을 제공합니다.
* 딥러닝 프레임워크는 아이디어를 전파하는 데 중요한 역할을 해왔습니다.손쉬운 모델링을 허용하는 1세대 프레임워크에는 [Caffe](https://github.com/BVLC/caffe), [Torch](https://github.com/torch) 및 [Theano](https://github.com/Theano/Theano)이 포함되었습니다.이러한 도구를 사용하여 많은 정액 논문이 작성되었습니다.지금까지 그들은 [TensorFlow](https://github.com/tensorflow/tensorflow) (높은 수준의 API [Keras](https://github.com/keras-team/keras)를 통해 자주 사용됨), [CNTK](https://github.com/Microsoft/CNTK), [Caffe 2](https://github.com/caffe2/caffe2) 및 [Apache MXNet](https://github.com/apache/incubator-mxnet)으로 대체되었습니다.3세대 도구, 즉 딥 러닝을 위한 필수 도구는 모델을 설명하기 위해 Python NumPy와 유사한 구문을 사용하는 [Chainer](https://github.com/chainer/chainer)가 주도했습니다.이 아이디어는 [PyTorch](https://github.com/pytorch/pytorch), MXNet의 [Gluon API](https://github.com/apache/incubator-mxnet), 그리고 [Jax](https://github.com/google/jax)에 의해 채택되었습니다.

더 나은 도구를 구축하는 시스템 연구자와 더 나은 신경망을 구축하는 통계 모델러 간의 노동 분업은 일을 크게 단순화했습니다.예를 들어, 선형 로지스틱 회귀 모델을 훈련시키는 것은 사소한 숙제 문제였으며, 2014년 카네기 멜론 대학교의 새로운 기계 학습 박사 과정 학생들에게 줄 가치가 있었습니다.이제 이 작업은 10줄 미만의 코드로 수행할 수 있으므로 프로그래머가 쉽게 파악할 수 있습니다.

## 성공 스토리

AI는 다른 방법으로는 달성하기 어려운 결과를 제공해 온 오랜 역사를 가지고 있습니다.예를 들어 광학 문자 인식을 사용하는 우편물 분류 시스템은 1990 년대부터 배포되었습니다.결국 이것은 유명한 MNIST 필기 숫자 데이터 세트의 소스입니다.은행 예금에 대한 수표를 읽고 신청자의 신용도를 채점하는 경우에도 동일하게 적용됩니다.금융 거래는 사기 여부를 자동으로 확인합니다.이는 페이팔, 스트라이프, 알리페이, 위챗, 애플, 비자 및 마스터카드와 같은 많은 전자 상거래 결제 시스템의 중추를 형성합니다.체스를 위한 컴퓨터 프로그램은 수십 년 동안 경쟁력이 있습니다.머신 러닝은 인터넷에서 검색, 추천, 개인화 및 순위를 제공합니다.즉, 머신 러닝은 눈에 보이지 않는 경우가 많지만 널리 퍼져 있습니다.

최근에는 AI가 각광을 받았는데, 이는 주로 이전에는 다루기 힘든 것으로 간주되고 소비자와 직접 관련이있는 문제에 대한 해결책으로 인해 각광을 받았습니다.이러한 발전 중 상당수는 딥 러닝에 기인합니다.

* 애플의 시리, 아마존의 알렉사, 구글의 어시스턴트와 같은 지능형 어시스턴트는 합리적인 정확도로 음성 질문에 답할 수 있습니다.여기에는 조명 스위치를 켜고 (장애인에게 도움이 됨) 이발사의 약속을 정하고 전화 지원 대화 상자를 제공하는 것과 같은 사소한 작업이 포함됩니다.이것은 AI가 우리 삶에 영향을 미치고 있다는 가장 눈에 띄는 신호일 것입니다.
* 디지털 어시스턴트의 핵심 요소는 음성을 정확하게 인식하는 능력입니다.점차적으로 이러한 시스템의 정확성은 특정 응용 분야 :cite:`Xiong.Wu.Alleva.ea.2018`에 대해 인간 평등에 도달하는 지점까지 증가했습니다.
* 물체 인식도 마찬가지로 먼 길을 왔습니다.2010년에는 사진에서 물체를 추정하는 것이 상당히 어려운 작업이었습니다.ImageNet 벤치마크에서 NEC 연구소와 일리노이 대학교 어바나-샴페인의 연구원들은 28% :cite:`Lin.Lv.Zhu.ea.2010`의 상위 5위 오류율을 달성했습니다.2017년까지 이 오류율은 2.25% :cite:`Hu.Shen.Sun.2018`로 감소했습니다.마찬가지로 새를 식별하거나 피부암을 진단하는 데 놀라운 결과가 달성되었습니다.
* 게임은 예전에는 인간 지능의 보루였습니다.시간차 강화 학습, 알고리즘 및 계산 진행을 사용하여 주사위 놀이를 하는 프로그램인 TD-Gammon을 시작으로 광범위한 응용 분야에 대한 알고리즘이 개발되었습니다.주사위 놀이와 달리 체스는 훨씬 더 복잡한 상태 공간과 일련의 행동을 가지고 있습니다.DeepBlue는 대규모 병렬 처리, 특수 목적 하드웨어 및 게임 트리 :cite:`Campbell.Hoane-Jr.Hsu.2002`을 통한 효율적인 검색을 사용하여 게리 카스파로프를 이겼습니다.거대한 주 공간으로 인해 Go는 여전히 더 어렵습니다.AlphaGo는 2015년 몬테카를로 나무 샘플링 :cite:`Silver.Huang.Maddison.ea.2016`와 결합된 딥 러닝을 사용하여 인간 평등에 도달했습니다.포커의 과제는 상태 공간이 크고 완전히 관찰되지 않는다는 것입니다 (상대방의 카드를 알지 못합니다).Libratus는 효율적으로 구조화 된 전략 :cite:`Brown.Sandholm.2017`를 사용하여 포커에서 인간의 성과를 능가했습니다.이것은 게임의 놀라운 발전과 고급 알고리즘이 게임에서 중요한 역할을했다는 사실을 보여줍니다.
* AI의 발전을 나타내는 또 다른 징후는 자율 주행 자동차와 트럭의 출현입니다.완전한 자율성은 아직 도달 할 수 없지만 Tesla, NVIDIA 및 Waymo와 같은 회사가 최소한 부분적인 자율성을 가능하게하는 제품을 선적하면서 이러한 방향으로 탁월한 진전이 이루어졌습니다.완전한 자율성을 매우 어렵게 만드는 것은 적절한 운전을 위해서는 규칙을 인식하고 추론하고 시스템에 통합하는 능력이 필요하다는 것입니다.현재 딥 러닝은 주로 이러한 문제의 컴퓨터 비전 측면에서 사용됩니다.나머지는 엔지니어가 크게 조정합니다.

다시 말하지만, 위의 목록은 기계 학습이 실제 응용 프로그램에 영향을 미친 부분의 표면을 거의 긁지 않습니다.예를 들어, 로봇 공학, 물류, 전산 생물학, 입자 물리학 및 천문학은 적어도 부분적으로 기계 학습에 대한 가장 인상적인 최근 발전 중 일부를 빚지고 있습니다.따라서 기계 학습은 엔지니어와 과학자에게 유비쿼터스 도구가 되고 있습니다.

AI에 대한 비 기술적 기사에서 AI 종말 또는 AI 특이성에 대한 질문이 제기되는 경우가 많습니다.두려움은 어떻게 든 기계 학습 시스템이 지각이 생기고 인간의 생계에 직접적인 영향을 미치는 것에 대해 프로그래머 (및 마스터) 와 독립적으로 결정할 것입니다.AI는 어느 정도까지 이미 인간의 생계에 즉각적인 영향을 미칩니다. 신용도는 자동으로 평가되고, 자동 조종 장치는 대부분 차량을 탐색하고, 보석금을 부여할지 여부에 대한 결정은 통계 데이터를 입력으로 사용합니다.좀 더 경솔하게 Alexa에게 커피 머신을 켜도록 요청할 수 있습니다.

다행히도 우리는 인간 제작자를 조작하거나 커피를 태울 준비가 된 지각있는 AI 시스템과는 거리가 멀다.첫째, AI 시스템은 구체적이고 목표 지향적인 방식으로 설계, 교육 및 배포됩니다.그들의 행동은 일반 지능의 환상을 줄 수 있지만 설계의 기초가되는 규칙, 휴리스틱 및 통계 모델의 조합입니다.둘째, 현재 자신을 향상시키고, 자신에 대해 추론하고, 일반적인 작업을 해결하려고 노력하면서 자체 아키텍처를 수정, 확장 및 개선 할 수있는*인공 일반 지능*을위한 도구는 존재하지 않습니다.

훨씬 더 시급한 관심사는 일상 생활에서 AI가 어떻게 사용되고 있는지입니다.트럭 운전사와 상점 보조원이 수행하는 많은 사소한 작업이 자동화 될 수 있고 자동화 될 가능성이 높습니다.농장 로봇은 유기 농업 비용을 줄일 수 있지만 수확 작업도 자동화 할 것입니다.트럭 운전사와 상점 보조원이 많은 국가에서 가장 흔한 직업 중 일부이기 때문에 산업 혁명의 이러한 단계는 많은 사회에 중대한 영향을 미칠 수 있습니다.또한 통계 모델을 신경 쓰지 않고 적용하면 인종, 성별 또는 연령 편향으로 이어질 수 있으며 결과적 결정을 내리기 위해 자동화되면 절차 적 공정성에 대한 합리적인 우려를 제기 할 수 있습니다.이러한 알고리즘을 주의해서 사용하는 것이 중요합니다.오늘날 우리가 알고있는 바에 따르면, 이것은 인류를 파괴 할 악의적 인 초지능의 잠재력보다 훨씬 더 시급한 우려를 불러 일으 킵니다.

## 제품 특징

지금까지 우리는 AI의 한 분야이자 AI에 대한 접근 방식인 기계 학습에 대해 광범위하게 이야기했습니다.딥 러닝은 머신 러닝의 하위 집합이지만 어지러운 알고리즘과 응용 프로그램 집합으로 인해 딥 러닝의 특정 요소가 무엇인지 평가하기가 어렵습니다.거의 모든 구성 요소가 대체 가능하기 때문에 피자에 필요한 재료를 고정하는 것만 큼 어렵습니다.

앞서 설명했듯이 기계 학습은 데이터를 사용하여 음성 인식에서 오디오를 텍스트로 변환하는 것과 같이 입력과 출력 간의 변환을 학습 할 수 있습니다.그렇게 할 때 알고리즘이 이러한 표현을 출력으로 변환하는 데 적합한 방식으로 데이터를 표현해야 하는 경우가 많습니다.
*딥 러닝*은 정확히*깊은*입니다.
모델이 여러 개의*레이어*변환을 학습하며, 각 레이어는 한 수준에서 표현을 제공합니다.예를 들어 입력값 근처의 계층은 데이터의 하위 수준 세부 정보를 나타낼 수 있지만 분류 출력에 더 가까운 계층은 차별에 사용되는 더 추상적인 개념을 나타낼 수 있습니다.*표현 학습*은 표현 자체를 찾는 것을 목표로 하기 때문에 딥 러닝을 다단계 표현 학습이라고 할 수 있습니다.

원시 오디오 신호, 이미지의 원시 픽셀 값 또는 임의의 길이의 문장과 외국어로 된 문장 간의 매핑과 같이 지금까지 논의한 문제는 딥 러닝이 뛰어나고 전통적인 기계 학습 방법이 흔들리는 문제입니다.이러한 다계층 모델은 이전 도구로는 할 수 없었던 방식으로 낮은 수준의 지각 데이터를 처리 할 수 있음이 밝혀졌습니다.딥 러닝 방법에서 가장 중요한 공통점은*엔드 투 엔드 트레이닝*을 사용하는 것입니다.즉, 개별적으로 튜닝된 구성 요소를 기반으로 시스템을 어셈블하는 대신 시스템을 구축한 다음 공동으로 성능을 조정합니다.예를 들어, 컴퓨터 비전에서 과학자들은*기능 엔지니어링* 프로세스를 기계 학습 모델 구축 프로세스와 분리했습니다.캐니 에지 검출기 :cite:`Canny.1987`와 로우의 SIFT 특징 추출기 :cite:`Lowe.2004`는 이미지를 특징 벡터로 매핑하는 알고리즘으로 10년 넘게 최고를 통치했습니다.과거에는 이러한 문제에 머신 러닝을 적용하는 데 있어 중요한 부분은 데이터를 얕은 모델에 적용할 수 있는 형태로 변환하는 수동 엔지니어링 방법을 고안하는 것이었습니다.안타깝게도 알고리즘에 의해 자동으로 수행되는 수백만 가지 선택에 대한 일관된 평가와 비교할 때 인간이 독창적으로 달성 할 수있는 것은 거의 없습니다.딥 러닝이 이어졌을 때 이러한 특징 추출기는 자동으로 튜닝된 필터로 대체되어 뛰어난 정확도를 제공했습니다.

따라서 딥 러닝의 주요 이점 중 하나는 기존 학습 파이프라인의 끝에 있는 얕은 모델뿐만 아니라 기능 엔지니어링의 노동 집약적인 프로세스를 대체한다는 것입니다.또한 딥 러닝은 도메인별 전처리의 대부분을 대체함으로써 이전에 컴퓨터 비전, 음성 인식, 자연어 처리, 의료 정보학 및 기타 응용 분야를 분리했던 많은 경계를 제거하여 다양한 문제를 해결할 수 있는 통합 도구 세트를 제공합니다.문제들.

엔드 투 엔드 교육 외에도 파라메트릭 통계 설명에서 완전 비모수적 모델로의 전환을 경험하고 있습니다.데이터가 부족한 경우 유용한 모델을 얻기 위해 현실에 대한 가정을 단순화하는 데 의존해야 합니다.데이터가 많으면 현실에 더 정확하게 맞는 비모수적 모델로 대체할 수 있습니다.이것은 컴퓨터의 가용성과 함께 이전 세기 중반에 물리학이 경험했던 진보를 어느 정도 반영합니다.전자가 손으로 어떻게 행동하는지에 대한 매개 변수 근사치를 푸는 대신 이제 관련 편미분 방정식의 수치 시뮬레이션에 의지 할 수 있습니다.이로 인해 종종 설명 가능성을 희생하더라도 훨씬 더 정확한 모델이 생성되었습니다.

이전 연구와의 또 다른 차이점은 최적이 아닌 해를 받아들이고, 비볼록 비선형 최적화 문제를 처리하고, 이를 증명하기 전에 시도하려는 의지입니다.통계적 문제를 다루는 이러한 새로운 경험주의와 재능의 급속한 유입이 결합되어 많은 경우 수십 년 동안 존재했던 도구를 수정하고 재발명하는 데 희생되었지만 실제 알고리즘의 빠른 발전으로 이어졌습니다.

결국 딥 러닝 커뮤니티는 학술 및 기업 경계를 넘어 도구를 공유하고 많은 우수한 라이브러리, 통계 모델 및 훈련 된 네트워크를 오픈 소스로 공개하는 것에 자부심을 가지고 있습니다.이 책을 구성하는 공책은 자유롭게 배포하고 사용할 수 있다는 것이 이러한 정신입니다.우리는 모든 사람이 딥 러닝에 대해 배울 수 있도록 액세스 장벽을 낮추기 위해 열심히 노력했으며 독자들이 이러한 혜택을 누릴 수 있기를 바랍니다.

## 요약

* 머신 러닝은 컴퓨터 시스템이 경험 (종종 데이터) 을 활용하여 특정 작업의 성능을 향상시키는 방법을 연구합니다.통계, 데이터 마이닝 및 최적화의 아이디어를 결합합니다.AI 솔루션을 구현하는 수단으로 사용되는 경우가 많습니다.
* 기계 학습의 한 클래스인 표현 학습은 데이터를 나타내는 적절한 방법을 자동으로 찾는 방법에 중점을 둡니다.딥러닝은 여러 변환 계층을 학습하여 다중 레벨 표현 학습입니다.
* 딥 러닝은 기존 머신 러닝 파이프라인의 끝부분에 있는 얕은 모델뿐만 아니라 기능 엔지니어링의 노동 집약적인 프로세스를 대체합니다.
* 최근 딥 러닝의 진전의 대부분은 값싼 센서와 인터넷 규모의 애플리케이션에서 발생하는 풍부한 데이터와 주로 GPU를 통한 계산의 상당한 발전으로 인해 촉발되었습니다.
* 전체 시스템 최적화는 고성능을 얻기 위한 핵심 요소입니다.효율적인 딥 러닝 프레임워크의 가용성으로 인해 설계 및 구현이 훨씬 쉬워졌습니다.

## 연습문제

1. 현재 작성 중인 코드의 어떤 부분을 “학습”할 수 있습니까? 즉, 코드에서 선택한 디자인을 학습하고 자동으로 결정하여 개선할 수 있습니까?코드에 휴리스틱 디자인 선택 사항이 포함되어 있습니까?
1. 문제를 해결하는 방법에 대한 많은 예가 있지만 문제를 자동화하는 구체적인 방법은 없습니까?이는 딥 러닝을 사용하기 위한 주요 후보가 될 수 있습니다.
1. AI의 발전을 새로운 산업 혁명으로 볼 때 알고리즘과 데이터의 관계는 무엇입니까?증기 기관이나 석탄과 비슷한가요?근본적인 차이점은 무엇입니까?
1. :numref:`fig_ml_loop`, 물리학, 공학 및 계량학과 같은 엔드 투 엔드 교육 접근 방식을 적용할 수 있는 다른 곳은 어디입니까?

[Discussions](https://discuss.d2l.ai/t/22)

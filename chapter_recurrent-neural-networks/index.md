# 순환 신경망
:label:`chap_rnn`

지금까지 테이블 형식 데이터와 이미지 데이터의 두 가지 유형의 데이터가 발생했습니다.후자의 경우 정규성을 활용하기 위해 특수 레이어를 설계했습니다.즉, 이미지의 픽셀을 순회한다면 아날로그 TV 시대의 테스트 패턴의 배경과 매우 흡사 한 내용의 내용을 추론하기가 훨씬 더 어려울 것입니다. 

가장 중요한 것은 지금까지 데이터가 모두 일부 분포에서 도출되고 모든 예제가 독립적이고 동일하게 분포되어 있다고 암묵적으로 가정했습니다 (즉).안타깝게도 대부분의 데이터에는 해당되지 않습니다.예를 들어, 이 단락의 단어는 순서대로 작성되었으며 무작위로 순열되면 그 의미를 해독하기가 매우 어려울 것입니다.마찬가지로 비디오의 이미지 프레임, 대화의 오디오 신호 및 웹 사이트에서의 탐색 동작은 모두 순차적 순서를 따릅니다.따라서 이러한 데이터에 대한 특수 모델이 데이터를 설명하는 데 더 잘 수행된다고 가정하는 것이 합리적입니다. 

또 다른 문제는 시퀀스를 입력으로 수신할 뿐만 아니라 시퀀스를 계속할 것으로 예상될 수 있다는 사실에서 발생합니다.예를 들어, 작업은 $2, 4, 6, 8, 10, \ldots$ 시리즈를 계속하는 것일 수 있습니다. 이는 시계열 분석에서 주식 시장, 환자의 발열 곡선 또는 경주 용 자동차에 필요한 가속을 예측하는 데 매우 일반적입니다.다시 우리는 이러한 데이터를 처리할 수 있는 모델을 갖고 싶습니다. 

간단히 말해서 CNN은 공간 정보를 효율적으로 처리할 수 있지만*순환 신경망* (RNN) 은 순차적 정보를 더 잘 처리하도록 설계되었습니다.RNN은 현재 입력과 함께 과거 정보를 저장하는 상태 변수를 도입하여 현재 출력을 결정합니다. 

순환 네트워크를 사용하는 많은 예는 텍스트 데이터를 기반으로 합니다.따라서 이 장에서는 언어 모델을 강조하겠습니다.시퀀스 데이터를 좀 더 공식적으로 검토한 후 텍스트 데이터를 전처리하는 실용적인 기법을 소개합니다.다음으로 언어 모델의 기본 개념에 대해 논의하고 이 토론을 RNN 설계의 영감으로 사용합니다.마지막으로 RNN이 이러한 네트워크를 훈련시킬 때 발생할 수있는 문제를 탐구하는 기울기 계산 방법을 설명합니다.

```toc
:maxdepth: 2

sequence
text-preprocessing
language-models-and-dataset
rnn
rnn-scratch
rnn-concise
bptt
```

# 지역 기반 CNN (R-CNN)
:label:`sec_rcnn`

:numref:`sec_ssd`에 설명된 단발 멀티박스 탐지 외에도 지역 기반 CNN 또는 CNN 기능 (R-CNN) 이 있는 영역은 객체 감지 :cite:`Girshick.Donahue.Darrell.ea.2014`에 딥 러닝을 적용하는 많은 선구적인 접근 방식 중 하나입니다.이 섹션에서는 R-CNN과 일련의 개선 사항, 즉 빠른 R-CNN :cite:`Girshick.2015`, 더 빠른 R-CNN :cite:`Ren.He.Girshick.ea.2015` 및 마스크 R-CNN :cite:`He.Gkioxari.Dollar.ea.2017`에 대해 소개합니다.공간이 제한되어 있기 때문에 이러한 모델의 디자인에만 집중할 것입니다. 

## R-CNN

*R-CNN*은 먼저 입력 이미지에서 많은 (예: 2000) *지역 제안*을 추출하여 (예: 앵커 박스는 영역 제안으로 간주 될 수 있음) 클래스 및 경계 상자 (예: 오프셋) 에 레이블을 지정합니다. :cite:`Girshick.Donahue.Darrell.ea.2014` 그런 다음 CNN을 사용하여 각 지역 제안에 대해 순방향 전파를 수행하여특징.다음으로 각 지역 제안의 기능을 사용하여 이 지역 제안의 클래스 및 경계 상자를 예측합니다. 

![The R-CNN model.](../img/r-cnn.svg)
:label:`fig_r-cnn`

:numref:`fig_r-cnn`는 R-CNN 모델을 보여줍니다.보다 구체적으로 R-CNN은 다음 네 단계로 구성됩니다. 

1. *선택적 검색*을 수행하여 입력 이미지 :cite:`Uijlings.Van-De-Sande.Gevers.ea.2013`에서 여러 고품질 영역 제안을 추출합니다.이러한 제안 영역은 일반적으로 모양과 크기가 다른 여러 축척으로 선택됩니다.각 지역 제안에는 클래스와 지상 진실 경계 상자가 표시됩니다.
1. 사전 훈련된 CNN을 선택하고 출력 계층 앞에서 잘라냅니다.각 지역 제안의 크기를 네트워크에 필요한 입력 크기로 조정하고 순방향 전파를 통해 영역 제안에 대해 추출된 특징을 출력합니다. 
1. 추출된 기능과 각 지역 제안의 레이블이 지정된 클래스를 예로 들어 보겠습니다.여러 서포트 벡터 머신을 훈련시켜 객체를 분류합니다. 여기서 각 서포트 벡터 머신은 예제에 특정 클래스가 포함되어 있는지 여부를 개별적으로 결정합니다.
1. 각 지역 제안의 추출된 특징과 레이블이 지정된 경계 상자를 예로 들어 보겠습니다.선형 회귀 모델을 훈련시켜 실측 경계 상자를 예측합니다.

R-CNN 모델은 이미지 특징을 효과적으로 추출하기 위해 사전 훈련된 CNN을 사용하지만 속도가 느립니다.단일 입력 이미지에서 수천 개의 지역 제안을 선택한다고 상상해보십시오. 이를 위해서는 물체 감지를 수행하기 위해 수천 개의 CNN 전방 전파가 필요합니다.이러한 엄청난 컴퓨팅 부하로 인해 실제 응용 프로그램에서 R-CNN을 널리 사용할 수 없습니다. 

## 패스트 R-CNN

R-CNN의 주요 성능 병목 현상은 계산을 공유하지 않고 각 지역 제안에 대한 독립적 인 CNN 순방향 전파에 있습니다.이러한 영역에는 일반적으로 겹치기 때문에 독립적인 특징 추출은 많은 반복 계산을 수행합니다.R-CNN의*빠른 R-CNN*의 주요 개선 사항 중 하나는 CNN 순방향 전파가 전체 이미지 :cite:`Girshick.2015`에서만 수행된다는 것입니다.  

![The fast R-CNN model.](../img/fast-rcnn.svg)
:label:`fig_fast_r-cnn`

:numref:`fig_fast_r-cnn`는 빠른 R-CNN 모델에 대해 설명합니다.주요 계산은 다음과 같습니다. 

1. R-CNN과 비교할 때 고속 R-CNN에서 특징 추출을 위한 CNN의 입력은 개별 영역 제안이 아닌 전체 이미지입니다.또한, 이 CNN은 훈련이 가능합니다.입력 이미지가 주어지면 CNN 출력의 모양을 $1 \times c \times h_1  \times w_1$로 설정합니다.
1. 선택적 검색이 $n$ 지역 제안을 생성한다고 가정합니다.이러한 영역 제안 (모양이 다른) 은 CNN 출력에서 관심 영역 (모양이 다른) 을 표시합니다.그런 다음 이러한 관심 영역은 쉽게 연결될 수 있도록 동일한 모양 (예: 높이 $h_2$ 및 너비 $w_2$가 지정됨) 의 특징을 추가로 추출합니다.이를 달성하기 위해 고속 R-CNN은*관심 영역 (RoI) 풀링* 계층을 도입합니다. CNN 출력 및 영역 제안이 이 계층에 입력되어 모든 영역 제안에 대해 추가로 추출되는 형상 $n \times c \times h_2 \times w_2$의 연결된 특징을 출력합니다.
1. 완전 연결 계층을 사용하여 연결된 특징을 형상 $n \times d$의 출력으로 변환합니다. 여기서 $d$는 모델 설계에 따라 달라집니다.
1. 각 $n$ 지역 제안에 대한 클래스 및 경계 상자를 예측합니다.보다 구체적으로, 클래스 및 경계 상자 예측에서 완전히 연결된 계층 출력을 형상 $n \times q$ ($q$는 클래스 수) 의 출력값과 형상 $n \times 4$의 출력으로 각각 변환합니다.클래스 예측에서는 소프트맥스 회귀를 사용합니다.

고속 R-CNN에서 제안된 관심 영역 풀링 계층은 :numref:`sec_pooling`에 도입된 풀링 계층과 다릅니다.풀링 계층에서는 풀링 창, 패딩 및 스트라이드의 크기를 지정하여 출력 모양을 간접적으로 제어합니다.반대로 관심 영역 풀링 계층에서 출력 형상을 직접 지정할 수 있습니다. 

예를 들어 각 영역의 출력 높이와 너비를 각각 $h_2$ 및 $w_2$로 지정해 보겠습니다.쉐이프가 $h \times w$인 관심 영역 창에 대해 이 창은 $h_2 \times w_2$ 그리드의 하위 창으로 나뉘며, 여기서 각 하위 창의 모양은 약 $(h/h_2) \times (w/w_2)$입니다.실제로 하위 창의 높이와 너비는 반올림되고 가장 큰 요소는 하위 창의 출력으로 사용됩니다.따라서 관심 영역 풀링 계층은 관심 영역의 모양이 서로 다른 경우에도 동일한 모양의 특징을 추출할 수 있습니다. 

예를 들어, :numref:`fig_roi`에서는 $4 \times 4$ 입력에서 왼쪽 상단 $3\times 3$ 관심 영역이 선택됩니다.이 관심 영역의 경우 $2\times 2$ 관심 영역 풀링 계층을 사용하여 $2\times 2$ 출력값을 얻습니다.분할된 4개의 하위 창 각각에는 요소 0, 1, 4, 5 (5가 최대값), 2와 6 (6이 최대값), 8과 9 (9가 최대값), 10이 포함됩니다. 

![A $2\times 2$ region of interest pooling layer.](../img/roi.svg)
:label:`fig_roi`

아래에서는 관심 영역 풀링 계층의 계산을 보여줍니다.CNN에서 추출한 피쳐 `X`의 높이와 너비가 모두 4이고 단일 채널만 있다고 가정합니다.

```{.python .input}
from mxnet import np, npx

npx.set_np()

X = np.arange(16).reshape(1, 1, 4, 4)
X
```

```{.python .input}
#@tab pytorch
import torch
import torchvision

X = torch.arange(16.).reshape(1, 1, 4, 4)
X
```

입력 이미지의 높이와 너비가 모두 40픽셀이고 선택적 검색이 이 이미지에 대해 두 개의 영역 제안을 생성한다고 가정해 보겠습니다.각 영역 제안은 다섯 가지 요소로 표현됩니다. 객체 클래스 뒤에 왼쪽 위 및 오른쪽 아래 모서리의 $(x, y)$ 좌표가 옵니다.

```{.python .input}
rois = np.array([[0, 0, 0, 20, 20], [0, 0, 10, 30, 30]])
```

```{.python .input}
#@tab pytorch
rois = torch.Tensor([[0, 0, 0, 20, 20], [0, 0, 10, 30, 30]])
```

`X`의 높이와 너비는 입력 영상의 높이와 너비의 $1/10$이므로 지정된 `spatial_scale` 인수에 따라 두 영역 제안의 좌표에 0.1을 곱합니다.그런 다음 두 관심 영역은 `X`에 각각 `X[:, :, 0:3, 0:3]` 및 `X[:, :, 1:4, 0:4]`로 표시됩니다.마지막으로 $2\times 2$ 관심 영역 풀링에서 각 관심 영역은 하위 창 그리드로 분할되어 동일한 형상 $2\times 2$의 특징을 추가로 추출합니다.

```{.python .input}
npx.roi_pooling(X, rois, pooled_size=(2, 2), spatial_scale=0.1)
```

```{.python .input}
#@tab pytorch
torchvision.ops.roi_pool(X, rois, output_size=(2, 2), spatial_scale=0.1)
```

## 더 빠른 R-CNN

물체 감지의 정확성을 높이기 위해 고속 R-CNN 모델은 일반적으로 선택적 검색에서 많은 지역 제안을 생성해야 합니다.정확도 손실 없이 지역 제안을 줄이기 위해*더 빠른 R-CNN*은 선택적 검색을*지역 제안 네트워크* :cite:`Ren.He.Girshick.ea.2015`로 대체할 것을 제안합니다. 

![The faster R-CNN model.](../img/faster-rcnn.svg)
:label:`fig_faster_r-cnn`

:numref:`fig_faster_r-cnn`는 더 빠른 R-CNN 모델을 보여줍니다.빠른 R-CNN과 비교할 때 R-CNN이 빠를수록 지역 제안 방법이 선택적 검색에서 지역 제안 네트워크로 변경됩니다.나머지 모델은 변경되지 않고 그대로 유지됩니다.지역 제안 네트워크는 다음 단계로 작동합니다. 

1. 패딩이 1인 $3\times 3$ 컨벌루션 계층을 사용하여 CNN 출력값을 $c$개 채널의 새 출력값으로 변환합니다.이러한 방식으로 CNN에서 추출한 특징 맵의 공간 차원을 따라 각 단위는 길이 $c$의 새로운 특징 벡터를 얻습니다.
1. 형상 맵의 각 픽셀을 중심으로 축척과 종횡비가 서로 다른 여러 앵커 상자를 생성하고 레이블을 지정합니다.
1. 각 앵커 상자의 중심에 있는 length-$c$ 특징 벡터를 사용하여 이 앵커 상자의 이진 클래스 (배경 또는 객체) 와 경계 상자를 예측합니다.
1. 예측된 클래스가 객체인 예측된 경계 상자를 생각해 보십시오.최대가 아닌 억제를 사용하여 겹친 결과를 제거합니다.객체에 대한 나머지 예측 경계 상자는 관심 영역 풀링 계층에 필요한 영역 제안입니다.

더 빠른 R-CNN 모델의 일부로 지역 제안 네트워크가 나머지 모델과 공동으로 훈련된다는 점은 주목할 가치가 있습니다.즉, 더 빠른 R-CNN의 목적 함수에는 객체 감지의 클래스 및 경계 상자 예측뿐만 아니라 영역 제안 네트워크에서 앵커 박스의 이진 클래스 및 경계 상자 예측도 포함됩니다.엔드 투 엔드 교육의 결과로 지역 제안 네트워크는 고품질 지역 제안을 생성하는 방법을 학습하여 데이터에서 학습되는 지역 제안 수를 줄임으로써 객체 감지의 정확성을 유지합니다. 

## 마스크 R-CNN

훈련 데이터 세트에서 물체의 픽셀 수준 위치도 이미지에 레이블이 지정되면*mask R-CNN*은 이러한 세부 레이블을 효과적으로 활용하여 물체 감지 :cite:`He.Gkioxari.Dollar.ea.2017`의 정확도를 더욱 향상시킬 수 있습니다. 

![The mask R-CNN model.](../img/mask-rcnn.svg)
:label:`fig_mask_r-cnn`

:numref:`fig_mask_r-cnn`에서 볼 수 있듯이 마스크 R-CNN은 더 빠른 R-CNN을 기반으로 수정됩니다.구체적으로, 마스크 R-CNN은 관심 영역 풀링 계층을
*관심 영역 (RoI) 정렬* 레이어입니다. 
이 관심 영역 정렬 레이어는 쌍선형 보간을 사용하여 피처 맵의 공간 정보를 보존하므로 픽셀 수준 예측에 더 적합합니다.이 레이어의 결과에는 모든 관심 영역에 대해 동일한 모양의 피처 맵이 포함됩니다.각 관심 영역에 대한 클래스와 경계 상자뿐만 아니라 추가 완전 컨벌루션 네트워크를 통해 객체의 픽셀 수준 위치를 예측하는 데 사용됩니다.이미지의 픽셀 수준 시맨틱을 예측하기 위해 완전 컨벌루션 네트워크를 사용하는 방법에 대한 자세한 내용은 이 장의 다음 섹션에서 설명합니다. 

## 요약

* R-CNN은 입력 이미지에서 많은 지역 제안을 추출하고 CNN을 사용하여 각 지역 제안에 대해 순방향 전파를 수행하여 특징을 추출한 다음 이러한 기능을 사용하여 이 지역 제안의 클래스 및 경계 상자를 예측합니다.
* R-CNN의 고속 R-CNN의 주요 개선 사항 중 하나는 CNN 순방향 전파가 전체 이미지에서만 수행된다는 것입니다.또한 관심 영역 풀링 계층을 도입하여 모양이 다른 관심 영역에 대해 동일한 모양의 특징을 추가로 추출할 수 있습니다.
* 더 빠른 R-CNN은 고속 R-CNN에서 사용되는 선택적 검색을 공동으로 훈련된 지역 제안 네트워크로 대체하므로 전자는 감소된 수의 지역 제안으로 물체 감지에서 정확성을 유지할 수 있습니다.
* 더 빠른 R-CNN을 기반으로 마스크 R-CNN은 픽셀 수준 레이블을 활용하여 객체 감지의 정확도를 더욱 향상시키기 위해 완전 컨벌루션 네트워크를 추가로 도입합니다.

## 연습문제

1. 객체 감지를 경계 상자 및 클래스 확률 예측과 같은 단일 회귀 문제로 구성할 수 있습니까?욜로 모델 :cite:`Redmon.Divvala.Girshick.ea.2016`의 설계를 참조할 수 있습니다.
1. 단발 멀티박스 감지를 이 섹션에 소개된 방법과 비교합니다.주요 차이점은 무엇입니까?:cite:`Zhao.Zheng.Xu.ea.2019`의 그림 2를 참조할 수 있습니다.

:begin_tab:`mxnet`
[Discussions](https://discuss.d2l.ai/t/374)
:end_tab:

:begin_tab:`pytorch`
[Discussions](https://discuss.d2l.ai/t/1409)
:end_tab:

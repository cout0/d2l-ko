# 서버 및 GPU 선택
:label:`sec_buy_gpu`

딥러닝 트레이닝에는 일반적으로 많은 양의 계산이 필요합니다.현재 GPU는 딥 러닝을 위한 가장 비용 효율적인 하드웨어 가속기입니다.특히 CPU와 비교할 때 GPU는 더 저렴하고 더 높은 성능을 제공합니다.또한 단일 서버에서 여러 GPU를 지원할 수 있으며, 하이엔드 서버의 경우 최대 8개의 GPU를 지원할 수 있습니다.보다 일반적인 수치는 엔지니어링 워크스테이션에 최대 4개의 GPU입니다. 열, 냉각 및 전력 요구 사항이 사무실 건물이 지원할 수 있는 것 이상으로 빠르게 확대되기 때문입니다.대규모 배포의 경우 아마존의 [P3](https://aws.amazon.com/ec2/instance-types/p3/) 및 [G4](https://aws.amazon.com/blogs/aws/in-the-works-ec2-instances-g4-with-nvidia-t4-gpus/) 인스턴스와 같은 클라우드 컴퓨팅이 훨씬 더 실용적인 솔루션입니다. 

## 서버 선택

많은 계산이 GPU에서 이루어지기 때문에 일반적으로 스레드가 많은 고급 CPU를 구입할 필요가 없습니다.즉, 파이썬의 GIL (전역 인터프리터 록) 으로 인해 CPU의 단일 스레드 성능은 GPU가 4-8개인 상황에서 중요할 수 있습니다.모든 것이 동일하므로 코어 수는 적지 만 클럭 주파수는 더 높은 CPU가 더 경제적 인 선택이 될 수 있습니다.예를 들어 6코어 4GHz와 8코어 3.5GHz CPU 중에서 선택할 때 전체 속도가 느리더라도 전자가 훨씬 바람직합니다.중요한 고려 사항은 GPU가 많은 전력을 사용하므로 많은 열을 방출한다는 것입니다.이를 위해서는 매우 우수한 냉각 성능과 GPU를 사용하기에 충분한 섀시가 필요합니다.가능하면 아래 지침을 따르십시오. 

1. **전원 공급 장치**.GPU는 상당한 양의 전력을 사용합니다.장치 당 최대 350W의 예산 (효율적인 코드는 많은 에너지를 사용할 수 있으므로 일반적인 수요 대신 그래픽 카드의 피크 수요* 확인).전원 공급 장치가 수요에 미치지 못하면 시스템이 불안정해질 수 있습니다.
1. **섀시 크기**.GPU가 크고 보조 전원 커넥터에는 종종 추가 공간이 필요합니다.또한 대형 섀시는 냉각하기가 더 쉽습니다.
1. **GPU 냉각**.GPU가 많은 경우 수냉에 투자하는 것이 좋습니다.또한 팬 수가 적더라도 장치 간 공기 흡입이 가능할 정도로 얇기 때문에*레퍼런스 디자인*을 목표로 하십시오.다중 팬 GPU를 구입하는 경우 여러 GPU를 설치할 때 충분한 공기를 확보하기에는 너무 두꺼워서 열 조절이 발생할 수 있습니다.
1. **PCIe 슬롯**.GPU에서 데이터를 이동하고 GPU 간에 데이터를 교환하려면 많은 대역폭이 필요합니다.레인이 16개인 PCIe 3.0 슬롯을 사용하는 것이 좋습니다.여러 GPU를 마운트하는 경우 마더 보드 설명을주의 깊게 읽고 여러 GPU를 동시에 사용할 수 있고 추가 슬롯에 PCIe 2.0이 아닌 PCIe 3.0을 사용할 수 있는지 확인하십시오.일부 마더보드는 여러 GPU가 설치된 상태에서 8배 또는 4배 대역폭으로 다운그레이드됩니다.이는 부분적으로 CPU가 제공하는 PCIe 레인 수 때문입니다.

간단히 말해, 딥 러닝 서버를 구축하기 위한 몇 가지 권장 사항은 다음과 같습니다. 

* **초보자**.전력 소비가 적은 저가형 GPU를 구입하십시오 (딥 러닝에 적합한 저렴한 게임 GPU는 150-200W를 사용합니다).운이 좋으면 현재 컴퓨터에서 지원할 것입니다.
* **1 GPU**.코어가 4개인 저가형 CPU는 충분하며 대부분의 마더보드로 충분합니다.최소 32GB DRAM을 목표로 하고 로컬 데이터 액세스를 위해 SSD에 투자하십시오.600W의 전원 공급 장치이면 충분합니다.팬이 많은 GPU를 구입하세요.
* **2 GPU**.코어가 4~6개인 로우엔드 CPU이면 충분합니다.64GB DRAM을 목표로 하고 SSD에 투자하십시오.두 개의 하이 엔드 GPU에는 1000W 순서가 필요합니다.메인보드와 관련하여*2개* PCIe 3.0 x16 슬롯이 있는지 확인하십시오.가능한 경우 추가 공기를 위해 PCIe 3.0 x16 슬롯 사이에 두 개의 여유 공간 (60mm 간격) 이있는 메인 보드를 구입하십시오.이 경우 팬이 많은 GPU를 두 개 구입하십시오.
* **4 GPU**.비교적 빠른 단일 스레드 속도 (즉, 높은 클럭 주파수) 의 CPU를 구입해야 합니다.AMD 스레드리퍼와 같이 PCIe 레인이 더 많은 CPU가 필요할 것입니다.PCIe 레인을 멀티플렉싱하기 위해 PLX가 필요하기 때문에 4 개의 PCIe 3.0 x16 슬롯을 얻으려면 상대적으로 비싼 메인 보드가 필요할 것입니다.레퍼런스 디자인이 좁은 GPU를 구입하여 GPU 사이에 공기를 공급하십시오.1600-2000W 전원 공급 장치가 필요하며 사무실의 콘센트에서 전원 공급 장치를 지원하지 않을 수 있습니다.이 서버는 아마*시끄럽고 뜨거운*으로 실행될 것입니다.책상 아래에 놓고 싶지 않습니다. 128GB의 DRAM을 사용하는 것이 좋습니다.로컬 스토리지용 SSD (1-2TB NVMe) 와 RAID 구성의 여러 하드 디스크를 사용하여 데이터를 저장할 수 있습니다.
* *8 GPU**.여러 개의 예비 전원 공급 장치가 있는 전용 다중 GPU 서버 섀시를 구입해야 합니다 (예: 전원 공급 장치당 1600W의 경우 2+1).이를 위해서는 듀얼 소켓 서버 CPU, 256GB ECC DRAM, 고속 네트워크 카드 (10GBE 권장) 가 필요하며 서버가 GPU의*물리적 폼 팩터*를 지원하는지 확인해야 합니다.공기 흐름과 배선 배치는 소비자와 서버 GPU에 따라 크게 다릅니다 (예: RTX 2080과 테슬라 V100).즉, 전원 케이블의 여유 공간이 부족하거나 적절한 배선 장치가 없기 때문에 서버에 소비자 GPU를 설치하지 못할 수 있습니다 (공동 저자 중 한 명이 고통스럽게 발견 한 것처럼).

## GPU 선택

현재 AMD와 NVIDIA는 전용 GPU의 두 가지 주요 제조업체입니다.NVIDIA는 딥 러닝 분야에 최초로 진출했으며 CUDA를 통해 딥 러닝 프레임워크에 대한 더 나은 지원을 제공합니다.따라서 대부분의 구매자는 NVIDIA GPU를 선택합니다. 

NVIDIA는 개별 사용자 (예: GTX 및 RTX 시리즈) 와 엔터프라이즈 사용자 (Tesla 시리즈를 통해) 를 대상으로 하는 두 가지 유형의 GPU를 제공합니다.두 가지 유형의 GPU는 비슷한 컴퓨팅 성능을 제공합니다.그러나 기업 사용자 GPU는 일반적으로 (수동) 강제 냉각, 더 많은 메모리 및 ECC (오류 수정) 메모리를 사용합니다.이러한 GPU는 데이터 센터에 더 적합하며 일반적으로 소비자 GPU보다 10배 더 비쌉니다. 

100개 이상의 서버를 보유한 대기업인 경우 NVIDIA Tesla 시리즈를 고려하거나 클라우드에서 GPU 서버를 사용해야 합니다.10개 이상의 서버를 보유한 실험실이나 중소기업의 경우 NVIDIA RTX 시리즈가 가장 비용 효율적일 수 있습니다.4-8개의 GPU를 효율적으로 수용하는 슈퍼마이크로 또는 Asus 섀시로 사전 구성된 서버를 구입할 수 있습니다. 

GPU 공급업체는 일반적으로 2017년에 출시된 GTX 1000 (파스칼) 시리즈와 2019년에 출시된 RTX 2000 (튜링) 시리즈와 같이 1~2년마다 새로운 세대를 출시합니다.각 시리즈는 서로 다른 성능 수준을 제공하는 여러 가지 모델을 제공합니다.GPU 성능은 주로 다음 세 가지 매개 변수의 조합입니다. 

1. **컴퓨팅 파워**.일반적으로 32비트 부동 소수점 컴퓨팅 파워를 찾습니다. 16비트 부동 소수점 훈련 (FP16) 도 주류로 진입하고 있습니다.예측에만 관심이 있는 경우 8비트 정수를 사용할 수도 있습니다.최신 세대의 튜링 GPU는 4비트 가속을 제공합니다.안타깝게도 현재 저정밀도 네트워크를 훈련시키는 알고리즘은 아직 널리 보급되어 있지 않습니다.
1. **메모리 크기**.모델이 커지거나 훈련 중에 사용되는 배치가 커지면 GPU 메모리가 더 많이 필요합니다.HBM2 (고대역폭 메모리) 와 GDDR6 (그래픽 DDR) 메모리를 확인합니다.HBM2는 더 빠르지 만 훨씬 비쌉니다.
1. **메모리 대역폭**.메모리 대역폭이 충분한 경우에만 컴퓨팅 성능을 최대한 활용할 수 있습니다.GDDR6 를 사용하는 경우 와이드 메모리 버스를 찾습니다.

대부분의 사용자는 컴퓨팅 파워를 살펴보는 것으로 충분합니다.많은 GPU가 서로 다른 유형의 가속을 제공합니다.예를 들어 NVIDIA의 텐서코어는 오퍼레이터의 하위 집합을 5배 가속화합니다.라이브러리에서 이 기능을 지원하는지 확인합니다.GPU 메모리는 4GB 이상이어야합니다 (8GB가 훨씬 좋음).GUI를 표시하기 위해 GPU를 사용하지 마십시오 (대신 내장 그래픽 사용).이를 피할 수 없는 경우 안전을 위해 2GB의 RAM을 추가합니다. 

:numref:`fig_flopsvsprice`는 다양한 GTX 900, GTX 1000 및 RTX 2000 시리즈 모델의 32비트 부동 소수점 컴퓨팅 성능과 가격을 비교합니다.가격은 위키백과에서 찾을 수 있는 권장 가격입니다. 

![Floating-point compute power and price comparison. ](../img/flopsvsprice.svg)
:label:`fig_flopsvsprice`

여러 가지를 볼 수 있습니다. 

1. 각 시리즈 내에서 가격과 성능은 대략 비례합니다.Titan 모델은 더 많은 양의 GPU 메모리의 이점을 위해 상당한 프리미엄을 요구합니다.그러나 최신 모델은 980 Ti와 1080 Ti를 비교하여 볼 수 있듯이 더 나은 비용 효율성을 제공합니다.RTX 2000 시리즈의 가격은 크게 개선되지 않는 것으로 보입니다.그러나 이는 훨씬 우수한 저정밀도 성능 (FP16, INT8 및 INT4) 을 제공하기 때문입니다.
2. GTX 1000 시리즈의 성능 대 비용 비율은 900 시리즈보다 약 2 배 더 큽니다.
3. RTX 2000 시리즈의 경우 가격은 가격의*아핀* 함수입니다.

![Floating-point compute power and energy consumption. ](../img/wattvsprice.svg)
:label:`fig_wattvsprice`

:numref:`fig_wattvsprice`는 에너지 소비가 계산량에 따라 대부분 선형적으로 확장되는 방식을 보여줍니다.둘째, 이후 세대가 더 효율적입니다.이는 RTX 2000 시리즈에 해당하는 그래프와 모순되는 것 같습니다.그러나 이것은 불균형하게 많은 에너지를 끌어들이는 TensorCores의 결과입니다. 

## 요약

* 서버를 구축할 때 전력, PCIe 버스 레인, CPU 단일 스레드 속도 및 냉각에 주의하십시오.
* 가능한 경우 최신 GPU 세대를 구입해야 합니다.
* 대규모 배포에 클라우드를 사용합니다.
* 고밀도 서버는 일부 GPU와 호환되지 않을 수 있습니다.구입하기 전에 기계 및 냉각 사양을 확인하십시오.
* 고효율을 위해 FP16 이하의 정밀도를 사용하십시오.

[Discussions](https://discuss.d2l.ai/t/425)

# 최적화 및 딥 러닝

이 섹션에서는 최적화와 딥러닝 간의 관계뿐만 아니라 딥러닝에서 최적화를 사용할 때의 과제에 대해 설명합니다.딥러닝 문제의 경우 일반적으로*손실 함수*를 먼저 정의합니다.손실 함수가 있으면 손실을 최소화하기 위해 최적화 알고리즘을 사용할 수 있습니다.최적화에서 손실 함수는 종종 최적화 문제의*목적 함수*라고 합니다.전통과 관례에 따라 대부분의 최적화 알고리즘은*최소화*와 관련이 있습니다.목표를 극대화해야 하는 경우 간단한 해결책이 있습니다. 목표의 부호를 뒤집기만 하면 됩니다. 

## 최적화의 목표

최적화는 딥 러닝의 손실 함수를 최소화하는 방법을 제공하지만 본질적으로 최적화와 딥 러닝의 목표는 근본적으로 다릅니다.전자는 주로 목적을 최소화하는 데 관심이 있지만 후자는 한정된 양의 데이터가 주어지면 적합한 모델을 찾는 데 관심이 있습니다.:numref:`sec_model_selection`에서는 이 두 목표의 차이점에 대해 자세히 논의했습니다.예를 들어, 훈련 오차와 일반화 오차는 일반적으로 다릅니다. 최적화 알고리즘의 목적 함수는 일반적으로 훈련 데이터 세트를 기반으로 한 손실 함수이므로 최적화의 목표는 훈련 오류를 줄이는 것입니다.그러나 딥 러닝 (또는 더 광범위하게 통계적 추론) 의 목표는 일반화 오류를 줄이는 것입니다.후자를 달성하려면 최적화 알고리즘을 사용하여 훈련 오차를 줄이는 것 외에도 과적합에 주의를 기울여야 합니다.

```{.python .input}
%matplotlib inline
from d2l import mxnet as d2l
from mpl_toolkits import mplot3d
from mxnet import np, npx
npx.set_np()
```

```{.python .input}
#@tab pytorch
%matplotlib inline
from d2l import torch as d2l
import numpy as np
from mpl_toolkits import mplot3d
import torch
```

```{.python .input}
#@tab tensorflow
%matplotlib inline
from d2l import tensorflow as d2l
import numpy as np
from mpl_toolkits import mplot3d
import tensorflow as tf
```

앞서 언급한 다양한 목표를 설명하기 위해 경험적 위험과 위험을 고려해 보겠습니다.:numref:`subsec_empirical-risk-and-risk`에 설명된 대로 경험적 위험은 훈련 데이터셋의 평균 손실이고 위험은 전체 데이터 모집단에서 예상되는 손실입니다.아래에서는 위험 함수 `f`과 경험적 위험 함수 `g`의 두 가지 함수를 정의합니다.한정된 양의 훈련 데이터만 있다고 가정해 보겠습니다.결과적으로 여기서 `g`는 `f`보다 덜 부드럽습니다.

```{.python .input}
#@tab all
def f(x):
    return x * d2l.cos(np.pi * x)

def g(x):
    return f(x) + 0.2 * d2l.cos(5 * np.pi * x)
```

아래 그래프는 훈련 데이터셋에 대한 경험적 위험의 최소값이 위험의 최소값과 다른 위치에 있을 수 있음을 보여줍니다 (일반화 오차).

```{.python .input}
#@tab all
def annotate(text, xy, xytext):  #@save
    d2l.plt.gca().annotate(text, xy=xy, xytext=xytext,
                           arrowprops=dict(arrowstyle='->'))

x = d2l.arange(0.5, 1.5, 0.01)
d2l.set_figsize((4.5, 2.5))
d2l.plot(x, [f(x), g(x)], 'x', 'risk')
annotate('min of\nempirical risk', (1.0, -1.2), (0.5, -1.1))
annotate('min of risk', (1.1, -1.05), (0.95, -0.5))
```

## 딥 러닝의 최적화 과제

이 장에서는 모델의 일반화 오류보다는 목적 함수를 최소화할 때 최적화 알고리즘의 성능에 중점을 둘 것입니다.:numref:`sec_linear_regression`에서는 최적화 문제에서 분석 솔루션과 수치 솔루션을 구별했습니다.딥러닝에서 대부분의 목적 함수는 복잡하고 분석 솔루션이 없습니다.대신 수치 최적화 알고리즘을 사용해야 합니다.이 장의 최적화 알고리즘은 모두 이 범주에 속합니다. 

딥 러닝 최적화에는 많은 어려움이 있습니다.가장 성가신 것들 중 일부는 로컬 최소값, 안장 점 및 사라지는 그라디언트입니다.그것들을 살펴보겠습니다. 

### 로컬 미니마

모든 목적 함수 $f(x)$의 경우 $x$의 $f(x)$의 값이 $x$ 부근의 다른 지점에서 $f(x)$의 값보다 작으면 $f(x)$가 국소 최솟값이 될 수 있습니다.$x$에서 $f(x)$의 값이 전체 영역에 대한 목적 함수의 최솟값인 경우 $f(x)$가 전역 최솟값입니다. 

예를 들어, 다음 함수가 주어지면 

$$f(x) = x \cdot \text{cos}(\pi x) \text{ for } -1.0 \leq x \leq 2.0,$$

이 함수의 국소 최솟값과 전역 최솟값을 근사화할 수 있습니다.

```{.python .input}
#@tab all
x = d2l.arange(-1.0, 2.0, 0.01)
d2l.plot(x, [f(x), ], 'x', 'f(x)')
annotate('local minimum', (-0.3, -0.25), (-0.77, -1.0))
annotate('global minimum', (1.1, -0.95), (0.6, 0.8))
```

딥러닝 모델의 목적 함수에는 일반적으로 국소 최적점이 많습니다.최적화 문제의 수치 해가 국소 최적에 가까운 경우, 최종 반복으로 얻은 수치 해는 목적 함수의 해의 기울기가 0에 가까워지거나 0이 될 때 목적 함수를*전역적으로* 대신*지역적으로*만 최소화할 수 있습니다.어느 정도의 노이즈만이 파라미터가 국소 최솟값에서 벗어날 수 있습니다.사실, 이것은 미니배치 확률적 경사 하강의 유익한 특성 중 하나이며, 미니배치에 대한 그래디언트의 자연적 변화가 국소 최솟값에서 파라미터를 제거할 수 있습니다. 

### 새들 포인트

로컬 최소값 외에도 안장 포인트가 그라디언트가 사라지는 또 다른 이유입니다.*안장 점*은 함수의 모든 기울기가 사라지지만 전역 또는 국소 최솟값이 아닌 모든 위치입니다.함수 $f(x) = x^3$를 고려해 보십시오.첫 번째 및 두 번째 파생물은 $x=0$에 대해 사라집니다.최소값은 아니더라도 이 시점에서 최적화가 중단될 수 있습니다.

```{.python .input}
#@tab all
x = d2l.arange(-2.0, 2.0, 0.01)
d2l.plot(x, [x**3], 'x', 'f(x)')
annotate('saddle point', (0, -0.2), (-0.52, -5.0))
```

아래 예제에서 볼 수 있듯이 더 높은 치수의 안장 지점은 훨씬 더 교활합니다.함수 $f(x, y) = x^2 - y^2$을 고려해 보십시오.안장 지점은 $(0, 0)$입니다.이는 $y$에 대한 최대값이며 $x$에 대한 최소값입니다.게다가 안장처럼 보이는***이 수학적 속성의 이름이 붙여진 곳입니다.

```{.python .input}
#@tab all
x, y = d2l.meshgrid(
    d2l.linspace(-1.0, 1.0, 101), d2l.linspace(-1.0, 1.0, 101))
z = x**2 - y**2

ax = d2l.plt.figure().add_subplot(111, projection='3d')
ax.plot_wireframe(x, y, z, **{'rstride': 10, 'cstride': 10})
ax.plot([0], [0], [0], 'rx')
ticks = [-1, 0, 1]
d2l.plt.xticks(ticks)
d2l.plt.yticks(ticks)
ax.set_zticks(ticks)
d2l.plt.xlabel('x')
d2l.plt.ylabel('y');
```

함수의 입력값이 $k$차원 벡터이고 출력값이 스칼라라고 가정하므로 헤세 행렬의 헤세 행렬은 $k$개의 고유값을 갖습니다 ([online appendix on eigendecompositions](https://d2l.ai/chapter_appendix-mathematics-for-deep-learning/eigendecomposition.html) 참조).함수의 해는 국소 최솟값, 국소 최댓값 또는 함수 기울기가 0인 위치의 안장 점일 수 있습니다. 

* 기울기가 0 인 위치에서 함수의 헤세 행렬의 고유값이 모두 양수이면 함수에 대한 국소 최솟값이 있습니다.
* 기울기가 0 인 위치에서 함수의 헤세 행렬의 고유값이 모두 음수이면 함수에 대한 국소 최댓값이 있습니다.
* 기울기가 0 인 위치에서 함수의 헤세 행렬의 고유값이 음수이고 양수이면 함수에 대한 안장이 생깁니다.

고차원 문제의 경우 고유값 중 최소*일부*가 음수일 가능성이 상당히 높습니다.이로 인해 안장 포인트가 로컬 미니마보다 가능성이 높아집니다.볼록성을 도입할 때 다음 섹션에서 이 상황에 대한 몇 가지 예외에 대해 논의할 것입니다.요컨대, 볼록 함수는 헤세 행렬의 고유값이 결코 음수가 아닌 함수입니다.하지만 안타깝게도 대부분의 딥러닝 문제는 이 범주에 속하지 않습니다.그럼에도 불구하고 최적화 알고리즘을 연구하는 데 훌륭한 도구입니다. 

### 사라지는 그라디언트

아마도 가장 교활한 문제는 사라지는 그라데이션일 것입니다.:numref:`subsec_activation-functions`에서 일반적으로 사용되는 활성화 함수와 그 파생물을 상기하십시오.예를 들어 함수 $f(x) = \tanh(x)$을 최소화하고 $x = 4$에서 시작한다고 가정합니다.보시다시피, $f$의 기울기는 nil에 가깝습니다.보다 구체적으로, $f'(x) = 1 - \tanh^2(x)$이며 따라서 $f'(4) = 0.0013$입니다.결과적으로 진행되기 전에 최적화가 오래 걸릴 것입니다.이는 ReLU 활성화 기능을 도입하기 전에 딥러닝 모델 학습이 매우 까다로웠던 이유 중 하나로 밝혀졌습니다.

```{.python .input}
#@tab all
x = d2l.arange(-2.0, 5.0, 0.01)
d2l.plot(x, [d2l.tanh(x)], 'x', 'f(x)')
annotate('vanishing gradient', (4, 1), (2, 0.0))
```

지금까지 살펴본 것처럼 딥 러닝을 위한 최적화에는 많은 어려움이 있습니다.다행히도 성능이 뛰어나고 초보자도 쉽게 사용할 수있는 강력한 알고리즘이 있습니다.또한*the* 최상의 솔루션을 찾을 필요가 없습니다.로컬 옵티마 또는 근사 솔루션은 여전히 매우 유용합니다. 

## 요약

* 훈련 오차를 최소화한다고해서 일반화 오차를 최소화하기 위해 최상의 파라미터 세트를 찾는다는 보장은*아닙니다.
* 최적화 문제에는 국소 최솟값이 많을 수 있습니다.
* 일반적으로 문제가 볼록하지 않기 때문에 문제에 더 많은 안장 지점이 있을 수 있습니다.
* 그라디언트가 사라지면 최적화가 지연될 수 있습니다.문제를 다시 매개변수화하는 것이 도움이 되는 경우가 많습니다.매개 변수를 올바르게 초기화하면 도움이 될 수 있습니다.

## 연습문제

1. 예를 들어 히든 레이어에 $d$ 차원으로 구성된 단일 은닉 레이어와 단일 출력값이 있는 간단한 MLP를 가정해 보겠습니다.모든 지역 최소 $d가 있다는 것을 보여주세요!동일하게 동작하는 $ 상응하는 해법.
1. 대칭 확률 행렬 $\mathbf{M}$이 있다고 가정합니다. 여기서 항목 $M_{ij} = M_{ji}$은 각각 일부 확률 분포 $p_{ij}$에서 추출됩니다.또한 $p_{ij}(x) = p_{ij}(-x)$, 즉 분포가 대칭이라고 가정합니다 (예: 자세한 내용은 :cite:`Wigner.1958` 참조).
    1. 고유값에 대한 분포도 대칭임을 입증합니다.즉, 임의의 고유 벡터 $\mathbf{v}$에 대해 연관된 고유값 $\lambda$이 $P(\lambda > 0) = P(\lambda < 0)$를 충족할 확률입니다.
    1. 위의 내용이 $P(\lambda > 0) = 0.5$를 의미하지 않는 이유는 무엇입니까?
1. 딥러닝 최적화와 관련된 다른 과제에는 어떤 것이 있을까요?
1. (실제) 안장에서 (실제) 공의 균형을 맞추고 싶다고 가정합니다.
    1. 왜 이게 어려운가요?
    1. 최적화 알고리즘에도 이 효과를 활용할 수 있습니까?

:begin_tab:`mxnet`
[Discussions](https://discuss.d2l.ai/t/349)
:end_tab:

:begin_tab:`pytorch`
[Discussions](https://discuss.d2l.ai/t/487)
:end_tab:

:begin_tab:`tensorflow`
[Discussions](https://discuss.d2l.ai/t/489)
:end_tab:

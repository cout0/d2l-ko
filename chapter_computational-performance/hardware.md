# 하드웨어
:label:`sec_hardware`

성능이 뛰어난 시스템을 구축하려면 문제의 통계적 측면을 포착하기 위해 알고리즘과 모델을 잘 이해해야 합니다.동시에 기본 하드웨어에 대해 최소한 어느 정도의 지식을 보유하는 것도 필수 불가결합니다.현재 섹션은 하드웨어 및 시스템 설계에 대한 적절한 과정을 대신 할 수 없습니다.대신 일부 알고리즘이 다른 알고리즘보다 효율적인 이유와 우수한 처리량을 달성하는 방법을 이해하는 출발점이 될 수 있습니다.좋은 설계는 규모 차수의 차이를 쉽게 만들 수 있으며, 이는 네트워크를 훈련시킬 수 있는 능력 (예: 일주일) 과 전혀 훈련하지 않는 것 (3개월 내에 마감일을 놓치음) 의 차이를 만들 수 있습니다.먼저 컴퓨터를 살펴보겠습니다.그런 다음 확대하여 CPU와 GPU를 좀 더 자세히 살펴보겠습니다.마지막으로 축소하여 서버 센터 또는 클라우드에서 여러 대의 컴퓨터가 어떻게 연결되어 있는지 검토합니다.  

![Latency Numbers that every programmer should know.](../img/latencynumbers.png)
:label:`fig_latencynumbers`

참을성이없는 독자는 :numref:`fig_latencynumbers`를 사용할 수 있습니다.지난 10 년 동안의 진행 상황에 대한 좋은 개요를 제공하는 콜린 스콧의 [대화 형 게시물](https://people.eecs.berkeley.edu/~rcs/research/interactive_latency.html) 에서 가져온 것입니다.원래 숫자는 제프 딘의 [Stanford talk from 2010](https://static.googleusercontent.com/media/research.google.com/en//people/jeff/Stanford-DL-Nov-2010.pdf) 때문입니다.아래 토론에서는 이러한 숫자에 대한 몇 가지 근거와 알고리즘 설계에 어떻게 도움이 될 수 있는지에 대해 설명합니다.아래의 논의는 매우 높은 수준이며 간단합니다.이는 분명히 적절한 과정을 대체하지 않음*이 아니라 통계 모델러가 적절한 설계 결정을 내릴 수 있도록 충분한 정보를 제공하기 위한 것입니다.컴퓨터 아키텍처에 대한 심층적 인 개요를 보려면 독자를 :cite:`Hennessy.Patterson.2011` 또는 [Arste Asanovic](http://inst.eecs.berkeley.edu/~cs152/sp19/) 과 같은 주제에 대한 최근 과정을 참조하십시오. 

## 컴퓨터

대부분의 딥 러닝 연구자와 실무자는 상당한 양의 메모리, 계산, GPU와 같은 가속기 형태 또는 그 배수를 갖춘 컴퓨터에 액세스 할 수 있습니다.컴퓨터는 다음과 같은 주요 구성 요소로 구성됩니다. 

* 프로세서 (CPU라고도 함) 는 일반적으로 8 개 이상의 코어로 구성된 운영 체제 및 기타 여러 가지를 실행하는 것 외에도 제공 한 프로그램을 실행할 수 있습니다.
* 메모리 (RAM) - 가중치 벡터와 활성화, 훈련 데이터와 같은 계산 결과를 저장하고 검색합니다.
* 속도가 1Gb/s ~ 100Gb/s 인 이더넷 네트워크 연결 (때로는 다중) 입니다. 고급 서버에서는 고급 상호 연결을 찾을 수 있습니다.
* 시스템을 하나 이상의 GPU에 연결하는 고속 확장 버스 (PCIe) 입니다.서버에는 최대 8 개의 가속기가 있으며 고급 토폴로지로 연결되는 경우가 많으며 데스크톱 시스템에는 사용자 예산 및 전원 공급 장치의 크기에 따라 1 또는 2 개가 있습니다.
* 마그네틱 하드 디스크 드라이브, 솔리드 스테이트 드라이브와 같은 내구성있는 스토리지는 대부분의 경우 PCIe 버스를 사용하여 연결됩니다.훈련 데이터를 시스템으로 효율적으로 전송하고 필요에 따라 중간 체크포인트를 저장할 수 있습니다.

![Connectivity of components of a computer.](../img/mobo-symbol.svg)
:label:`fig_mobo-symbol`

:numref:`fig_mobo-symbol`에서 알 수 있듯이 대부분의 구성 요소 (네트워크, GPU 및 스토리지) 는 PCIe 버스를 통해 CPU에 연결됩니다.CPU에 직접 연결된 여러 레인으로 구성됩니다.예를 들어 AMD의 스레드리퍼 3에는 64개의 PCIe 4.0 레인이 있으며, 각 레인은 양방향으로 16Gbit/s 데이터 전송이 가능합니다.메모리는 총 대역폭이 최대 100Gb/s인 CPU에 직접 연결됩니다. 

컴퓨터에서 코드를 실행할 때 데이터를 프로세서 (CPU 또는 GPU) 로 섞고 계산을 수행 한 다음 결과를 프로세서에서 RAM 및 내구성 있는 스토리지로 다시 이동해야합니다.따라서 좋은 성능을 얻으려면 시스템 중 하나가 큰 병목 현상이 되지 않고 원활하게 작동하는지 확인해야 합니다.예를 들어 이미지를 충분히 빨리 로드할 수 없는 경우 프로세서가 수행할 작업이 없습니다.마찬가지로 행렬을 CPU (또는 GPU) 로 충분히 빠르게 이동할 수 없으면 처리 요소가 굶어 죽을 것입니다.마지막으로 네트워크를 통해 여러 컴퓨터를 동기화하려는 경우 후자는 계산 속도를 늦추지 않아야합니다.한 가지 옵션은 통신과 계산을 인터리브하는 것입니다.다양한 구성 요소에 대해 자세히 살펴 보겠습니다. 

## 메모리

가장 기본적인 메모리는 쉽게 액세스 할 수 있어야하는 데이터를 저장하는 데 사용됩니다.현재 CPU RAM은 일반적으로 [DDR4](https://en.wikipedia.org/wiki/DDR4_SDRAM) 종류로 모듈당 20~25GB/s의 대역폭을 제공합니다.각 모듈에는 64비트 와이드 버스가 있습니다.일반적으로 여러 채널을 허용하기 위해 메모리 모듈 쌍이 사용됩니다.CPU에는 2~4개의 메모리 채널이 있습니다. 즉, 최대 메모리 대역폭이 4 0Gb/s에서 100Gb/s 사이입니다.채널당 두 개의 뱅크가 있는 경우가 많습니다.예를 들어 AMD의 Zen 3 스레드리퍼에는 8개의 슬롯이 있습니다. 

이 숫자는 인상적이지만 실제로 이야기의 일부만 알려줍니다.메모리에서 일부를 읽으려면 먼저 메모리 모듈에 정보를 찾을 수 있는 위치를 알려야 합니다.즉, 먼저*주소*를 RAM으로 보내야 합니다.이 작업이 완료되면 단일 64비트 레코드 또는 긴 레코드 시퀀스만 읽도록 선택할 수 있습니다.후자를*버스트 읽기*라고 합니다.간단히 말해서, 메모리에 주소를 보내고 전송을 설정하는 데 약 100ns가 걸립니다 (세부 사항은 사용되는 메모리 칩의 특정 타이밍 계수에 따라 다름). 모든 후속 전송에는 0.2ns 만 걸립니다.요컨대, 첫 번째 읽기는 후속 읽기보다 500 배 비쌉니다!초당 최대 10,000,000개의 임의 읽기를 수행할 수 있습니다.이는 가능한 한 랜덤 메모리 액세스를 피하고 대신 버스트 읽기 (및 쓰기) 를 사용한다는 것을 의미합니다. 

여러*은행*이 있다는 점을 고려하면 문제는 좀 더 복잡합니다.각 뱅크는 메모리를 거의 독립적으로 읽을 수 있습니다.이것은 두 가지를 의미합니다.한편, 랜덤 읽기의 유효 횟수는 메모리 전체에 고르게 분산되어 있는 경우 최대 4배 더 높습니다.또한 버스트 읽기도 4배 빠르기 때문에 임의 읽기를 수행하는 것은 여전히 좋지 않습니다.반면 메모리를 64비트 경계로 정렬하므로 모든 데이터 구조를 동일한 경계로 정렬하는 것이 좋습니다.컴파일러는 적절한 플래그가 설정되었을 때 거의 [automatically](https://en.wikipedia.org/wiki/Data_structure_alignment)를 수행합니다.호기심 많은 독자들은 [제샨 치슈티](http://web.cecs.pdx.edu/~zeshan/ece585_lec5.pdf) 의 강연과 같은 DRAM에 대한 강의를 검토하는 것이 좋습니다. 

GPU 메모리는 CPU보다 처리 요소가 더 많기 때문에 대역폭 요구 사항이 훨씬 더 높습니다.전반적으로 두 가지 옵션이 있습니다.첫 번째는 메모리 버스를 훨씬 넓게 만드는 것입니다.예를 들어 엔비디아의 RTX 2080 Ti에는 352비트 너비의 버스가 있습니다.이를 통해 훨씬 더 많은 정보를 동시에 전송할 수 있습니다.둘째, GPU는 특정 고성능 메모리를 사용합니다.엔비디아의 RTX 및 타이탄 시리즈와 같은 소비자 등급 디바이스는 일반적으로 총 대역폭이 500Gb/s 이상인 [GDDR6](https://en.wikipedia.org/wiki/GDDR6_SDRAM) 칩을 사용합니다.대안은 HBM (고대역폭 메모리) 모듈을 사용하는 것입니다.이들은 매우 다른 인터페이스를 사용하며 전용 실리콘 웨이퍼의 GPU와 직접 연결됩니다.따라서 비용이 매우 비싸고 일반적으로 NVIDIA Volta V100 시리즈 가속기와 같은 고급 서버 칩으로 사용이 제한됩니다.당연히 GPU 메모리는 전자의 비용이 높기 때문에 일반적으로 CPU 메모리보다 훨씬 작습니다.우리의 목적을 위해 전반적으로 성능 특성은 비슷하며 훨씬 빠릅니다.이 책의 목적에 따라 세부 사항을 무시할 수 있습니다.높은 처리량을 위해 GPU 커널을 튜닝할 때만 중요합니다. 

## 스토리지

RAM의 주요 특징 중 일부는*대역폭*과*지연 시간*이라는 것을 확인했습니다.저장 장치의 경우에도 마찬가지입니다. 차이가 훨씬 더 심할 수 있습니다. 

### 하드 디스크 드라이브

*하드 디스크 드라이브* (HDD) 는 반세기 이상 사용되어 왔습니다.간단히 말해서, 주어진 트랙에서 읽거나 쓸 수 있도록 배치 할 수있는 헤드가 달린 많은 회전 플래터가 포함되어 있습니다.하이엔드 디스크는 9개의 플래터에서 최대 16TB를 수용할 수 있습니다.HDD의 주요 이점 중 하나는 상대적으로 저렴하다는 것입니다.많은 단점 중 하나는 일반적으로 치명적인 오류 모드와 상대적으로 높은 읽기 대기 시간입니다.

후자를 이해하려면 HDD가 약 7,200RPM (분당 회전 수) 으로 회전한다는 사실을 고려하십시오.훨씬 빠르면 플래터에 가해지는 원심력으로 인해 부서질 것입니다.디스크의 특정 섹터에 액세스 할 때 큰 단점이 있습니다. 플래터가 제 위치에서 회전 할 때까지 기다려야합니다 (헤드를 움직일 수는 있지만 실제 디스크는 가속화 할 수 없음).따라서 요청한 데이터를 사용할 수 있을 때까지 8ms 이상이 걸릴 수 있습니다.일반적으로 HDD는 약 100IOPS (초당 입력/출력 작업) 로 작동할 수 있습니다.이 수치는 지난 20년 동안 본질적으로 변하지 않았습니다.더 나쁜 것은 대역폭을 늘리는 것도 똑같이 어렵다는 것입니다 (100-200MB/s 정도).결국 각 헤드는 비트 트랙을 읽으므로 비트 전송률은 정보 밀도의 제곱근으로 만 조정됩니다.그 결과 HDD는 매우 큰 데이터 세트를 위한 보관 스토리지 및 저급 스토리지로 빠르게 강등되고 있습니다. 

### 솔리드 스테이트 드라이브

솔리드 스테이트 드라이브 (SSD) 는 플래시 메모리를 사용하여 정보를 영구적으로 저장합니다.이렇게 하면 저장된 레코드에*훨씬 더 빨리* 액세스할 수 있습니다.최신 SSD는 10만 ~ 500,000IOPS로 작동할 수 있습니다. 즉, HDD보다 최대 3배 빠른 속도로 작동할 수 있습니다.또한 대역폭은 1—3Gb/s에 도달할 수 있습니다. 즉, HDD보다 한 배 더 빠릅니다.이러한 개선 사항은 사실이 되기에는 너무 좋게 들립니다.실제로 SSD 설계 방식으로 인해 다음과 같은 주의 사항이 있습니다. 

* SSD는 정보를 블록 (256KB 이상) 에 저장합니다.전체적으로 만 쓸 수 있으므로 상당한 시간이 걸립니다.결과적으로 SSD의 비트 단위 랜덤 쓰기는 성능이 매우 떨어집니다.마찬가지로 블록을 읽고 지운 다음 새 정보로 다시 써야하기 때문에 일반적으로 데이터를 쓰는 데 상당한 시간이 걸립니다.지금까지 SSD 컨트롤러와 펌웨어는 이를 완화하기 위한 알고리즘을 개발했습니다.그럼에도 불구하고 특히 QLC (쿼드 레벨 셀) SSD의 경우 쓰기 속도가 훨씬 느려질 수 있습니다.성능 향상을 위한 핵심은 작업의*대기열*을 유지하고, 읽기를 선호하며, 가능하면 큰 블록에 쓰는 것입니다.
* SSD의 메모리 셀은 비교적 빨리 마모됩니다 (종종 수천 번의 쓰기 후에).마모 수준 보호 알고리즘은 여러 셀에 성능 저하를 확산시킬 수 있습니다.즉, 파일 교환이나 로그 파일의 대규모 집계에 SSD를 사용하지 않는 것이 좋습니다.
* 마지막으로 대역폭이 크게 증가함에 따라 컴퓨터 설계자는 SSD를 PCIe 버스에 직접 연결해야했습니다.이를 처리할 수 있는 드라이브 (NVMe (비휘발성 메모리 향상) 는 최대 4개의 PCIe 레인을 사용할 수 있습니다.이는 PCIe 4.0에서 최대 8GB/s에 달합니다.

### 클라우드 스토리지

클라우드 스토리지는 구성 가능한 성능 범위를 제공합니다.즉, 가상 시스템에 스토리지를 할당하는 것은 사용자가 선택한 수량과 속도 측면에서 동적입니다.지연 시간이 너무 높을 때마다 (예: 작은 레코드가 많은 훈련 중) 프로비저닝된 IOP 수를 늘리는 것이 좋습니다. 

## CPU

중앙 처리 장치 (CPU) 는 모든 컴퓨터의 중심입니다.시스템 코드를 실행할 수 있는*프로세서 코어*, 이를 연결하는*버스* (특정 토폴로지는 프로세서 모델, 세대 및 공급업체마다 크게 다름) 및*캐시*와 같은 여러 주요 구성 요소로 구성되어 있습니다.주 메모리에서 읽을 수 있습니다.마지막으로, 거의 모든 최신 CPU에는 미디어 처리 및 기계 학습에서 일반적으로 사용되는 고성능 선형 대수 및 컨볼 루션을 지원하는*벡터 처리 장치*가 포함되어 있습니다. 

![Intel Skylake consumer quad-core CPU.](../img/skylake.svg)
:label:`fig_skylake`

:numref:`fig_skylake`는 인텔 스카이레이크 소비자 등급 쿼드코어 CPU를 나타냅니다.통합 GPU, 캐시 및 4개의 코어를 연결하는 링버스가 있습니다.이더넷, WiFi, 블루투스, SSD 컨트롤러 및 USB와 같은 주변 장치는 칩셋의 일부이거나 CPU에 직접 연결 (PCIe) 됩니다. 

### 마이크로아키텍처

각 프로세서 코어는 다소 정교한 구성 요소 세트로 구성됩니다.세대와 공급업체마다 세부 정보가 다르지만 기본 기능은 거의 표준입니다.프런트 엔드는 명령을 로드하고 어떤 경로를 사용할지 예측하려고 시도합니다 (예: 제어 흐름).그런 다음 명령어는 어셈블리 코드에서 마이크로 명령어로 디코딩됩니다.어셈블리 코드는 프로세서가 실행하는 최하위 레벨 코드가 아닌 경우가 많습니다.대신, 복잡한 명령어는 더 낮은 수준의 동작들의 집합으로 디코딩될 수 있다.그런 다음 실제 실행 코어에 의해 처리됩니다.종종 후자는 많은 작업을 동시에 수행 할 수 있습니다.예를 들어, :numref:`fig_cortexa77`의 ARM 코어 텍스 A77 코어는 최대 8개의 작업을 동시에 수행할 수 있습니다. 

![ARM Cortex A77 Microarchitecture.](../img/a77.svg)
:label:`fig_cortexa77`

즉, 효율적인 프로그램은 독립적으로 수행할 수 있는 경우 클럭 사이클당 둘 이상의 명령을 수행할 수 있습니다.모든 단위가 동일하게 생성되는 것은 아닙니다.일부는 정수 명령을 전문으로하는 반면 다른 일부는 부동 소수점 성능에 최적화되어 있습니다.처리량을 높이기 위해 프로세서는 분기 명령에서 여러 코드 경로를 동시에 따른 다음 취해지지 않은 분기의 결과를 버릴 수도 있습니다.이것이 가장 유망한 경로만 추구되도록 분기 예측 단위가 (프런트 엔드에서) 중요한 이유입니다. 

### 벡터화

딥 러닝은 컴퓨팅에 매우 많이 소모됩니다.따라서 CPU를 머신 러닝에 적합하게 만들려면 한 클록 사이클에서 많은 작업을 수행해야 합니다.이는 벡터 단위를 통해 이루어집니다.이름이 다릅니다. : on ARM they are called NEON, on x86 they (a recent generation) are referred to as [AVX2](https://en.wikipedia.org/wiki/Advanced_Vector_Extensions) units. A common aspect is that they are able to perform SIMD (single instruction multiple data) operations. :numref:`fig_neon128`는 ARM에서 한 클록 사이클에 8 개의 짧은 정수를 추가하는 방법을 보여줍니다. 

![128 bit NEON vectorization.](../img/neon128.svg)
:label:`fig_neon128`

아키텍처 선택에 따라 이러한 레지스터의 길이는 최대 512비트이므로 최대 64쌍의 숫자를 조합할 수 있습니다.예를 들어, 두 숫자를 곱하고 세 번째 숫자에 더할 수 있습니다. 이는 융합 곱셈-더하기라고도합니다.인텔의 [OpenVino](https://01.org/openvinotoolkit)는 이를 사용하여 서버급 CPU에서 딥 러닝을 위한 상당한 처리량을 달성합니다.하지만 이 수치는 GPU가 달성할 수 있는 능력에 따라 완전히 줄어듭니다.예를 들어 NVIDIA의 RTX 2080 Ti에는 4,352 개의 CUDA 코어가 있으며 각 코어는 언제든지 이러한 작업을 처리 할 수 있습니다. 

### 캐쉬

2GHz 주파수에서 실행되는 위의 : we have a modest CPU core with 4 cores as depicted in :numref:`fig_skylake`의 다음 상황을 고려하십시오.또한 IPC (클럭당 명령어 수) 수가 1이고 장치에 256비트 너비가 활성화된 AVX2가 있다고 가정해 보겠습니다.AVX2 연산에 사용되는 레지스터 중 적어도 하나를 메모리에서 검색해야한다고 가정 해 보겠습니다.이는 CPU가 클럭 사이클당 $4 \times 256 \text{ bit} = 128 \text{ bytes}$의 데이터를 소비한다는 것을 의미합니다.초당 프로세서로 $2 \times 10^9 \times 128 = 256 \times 10^9$ 바이트를 전송할 수 없다면 처리 요소가 굶어 죽을 것입니다.안타깝게도 이러한 칩의 메모리 인터페이스는 20~40Gb/s 데이터 전송만 지원합니다. 즉, 한 단계 더 작습니다.수정은 메모리에서 가능한 한 멀리*new* 데이터를 로드하지 않고 CPU에 로컬로 캐시하는 것입니다.이것이 바로 캐시가 유용한 곳입니다.일반적으로 다음과 같은 이름 또는 개념이 사용됩니다. 

* **레지스터**는 엄밀히 말하면 캐시의 일부가 아닙니다.무대 지침을 도와줍니다.즉, CPU 레지스터는 CPU가 지연 패널티 없이 클럭 속도로 액세스할 수 있는 메모리 위치입니다.CPU에는 수십 개의 레지스터가 있습니다.레지스터를 효율적으로 사용하는 것은 컴파일러 (또는 프로그래머) 에게 달려 있습니다.예를 들어 C 프로그래밍 언어에는 `register` 키워드가 있습니다.
* **L1 캐시**는 높은 메모리 대역폭 요구 사항에 대한 첫 번째 방어선입니다.L1 캐시는 크기가 작으며 (일반적인 크기는 32~64KB) 데이터 및 명령 캐시로 분할되는 경우가 많습니다.L1 캐시에서 데이터가 발견되면 액세스 속도가 매우 빠릅니다.여기서 찾을 수 없는 경우 검색은 캐시 계층 구조 아래로 진행됩니다.
* **L2 캐시**는 다음 정거장입니다.아키텍처 설계 및 프로세서 크기에 따라 배타적일 수 있습니다.지정된 코어에서만 액세스할 수 있거나 여러 코어 간에 공유할 수 있습니다.L2 캐시는 L1보다 크고 (일반적으로 코어당 256—512KB) 느립니다.또한 L2에서 무언가에 액세스하려면 먼저 데이터가 L1에 있지 않은지 확인해야 하며, 이로 인해 약간의 추가 지연 시간이 추가됩니다.
* **L3 캐시**는 여러 코어 간에 공유되며 상당히 클 수 있습니다.AMD의 Epyc 3 서버 CPU에는 여러 칩릿에 걸쳐 무려 256MB의 캐시가 분산되어 있습니다.보다 일반적인 숫자는 4~8MB 범위입니다.

다음에 필요한 메모리 요소를 예측하는 것은 칩 설계의 핵심 최적화 파라미터 중 하나입니다.예를 들어, 대부분의 캐싱 알고리즘은 역방향으로가 아니라*앞으로* 읽기를 시도하기 때문에*앞으로* 방향으로 메모리를 트래버스하는 것이 좋습니다.마찬가지로 메모리 액세스 패턴을 로컬로 유지하는 것이 성능을 향상시키는 좋은 방법입니다. 

캐시를 추가하는 것은 양날의 검입니다.한편으로는 프로세서 코어에 데이터가 부족하지 않도록합니다.동시에 칩 크기를 증가시켜 처리 능력을 높이는 데 소비될 수 있는 면적을 사용합니다.또한*캐시 누락*은 비용이 많이 들 수 있습니다.:numref:`fig_falsesharing`에 나와 있는 것처럼 최악의 시나리오인 *허위 공유*를 생각해 보십시오.프로세서 1의 스레드가 데이터를 요청할 때 메모리 위치가 프로세서 0에서 캐시됩니다.이를 얻으려면 프로세서 0이 수행하는 작업을 중지하고 정보를 다시 주 메모리에 기록한 다음 프로세서 1이 메모리에서 해당 정보를 읽도록 해야 합니다.이 작업 중에 두 프로세서가 모두 대기합니다.효율적인 단일 프로세서 구현과 비교할 때 이러한 코드는 다중 프로세서에서 더 느리게* 실행될 수 있습니다.이것이 캐시 크기 (물리적 크기 외에) 에 실질적인 제한이 있는 또 하나의 이유입니다. 

![False sharing (image courtesy of Intel).](../img/falsesharing.svg)
:label:`fig_falsesharing`

## GPU 및 기타 액셀러레이터

딥 러닝이 GPU 없이는 성공하지 못했을 것이라고 주장해도 과언이 아닙니다.마찬가지로 딥 러닝으로 인해 GPU 제조업체의 재산이 크게 증가했다고 주장하는 것이 합리적입니다.하드웨어와 알고리즘의 이러한 공진화는 더 좋든 나쁘 든 딥 러닝이 바람직한 통계 모델링 패러다임인 상황으로 이어졌습니다.따라서 GPU 및 TPU :cite:`Jouppi.Young.Patil.ea.2017`와 같은 관련 가속기의 특정 이점을 이해하는 것이 좋습니다. 

실제로 종종 구별되는 점이 있습니다. 액셀러레이터는 훈련 또는 추론에 최적화되어 있습니다.후자의 경우 네트워크에서 순방향 전파만 계산하면 됩니다.역전파를 위해 중간 데이터를 저장할 필요가 없습니다.또한 매우 정확한 계산이 필요하지 않을 수 있습니다 (일반적으로 FP16 또는 INT8이면 충분).반면에 훈련 중에 모든 중간 결과에는 그래디언트를 계산하기 위한 스토리지가 필요합니다.또한 그래디언트를 누적하려면 수치 언더플로우 (또는 오버플로) 를 방지하기 위해 더 높은 정밀도가 필요합니다이는 FP16 (또는 FP32와 혼합 정밀도) 이 최소 요구 사항임을 의미합니다.이 모든 작업에는 더 빠르고 더 큰 메모리 (HBM2 대 GDDR6) 와 더 많은 처리 능력이 필요합니다.예를 들어, NVIDIA의 [Turing](https://devblogs.nvidia.com/nvidia-turing-architecture-in-depth/) T4 GPU는 추론에 최적화되어 있지만 V100 GPU는 교육에 더 적합합니다. 

:numref:`fig_neon128`에 설명된 대로 벡터화를 리콜합니다.프로세서 코어에 벡터 유닛을 추가하면 처리량을 크게 높일 수 있었습니다.예를 들어 :numref:`fig_neon128`의 예에서는 16개의 작업을 동시에 수행할 수 있었습니다.먼저, 벡터 간의 연산뿐만 아니라 행렬 간의 연산도 최적화하는 연산을 추가하면 어떻게 될까요?이 전략으로 인해 텐서 코어가 생성되었습니다 (곧 다룰 예정).둘째, 코어를 더 추가하면 어떻게 될까요?간단히 말해서, 이 두 전략은 GPU의 설계 결정을 요약합니다. :numref:`fig_turing_processing_block`는 기본 처리 블록에 대한 개요를 제공합니다.16개의 정수와 16개의 부동 소수점 단위를 포함합니다.또한 두 개의 텐서 코어가 딥 러닝과 관련된 추가 작업의 좁은 하위 집합을 가속화합니다.각 스트리밍 멀티프로세서는 이러한 블록 4개로 구성됩니다. 

![NVIDIA Turing processing block (image courtesy of NVIDIA).](../img/turing-processing-block.png)
:width:`150px`
:label:`fig_turing_processing_block`

다음으로 12개의 스트리밍 멀티프로세서가 하이엔드 TU102 프로세서를 구성하는 그래픽 처리 클러스터로 그룹화됩니다.충분한 메모리 채널과 L2 캐시가 설정을 보완합니다. :numref:`fig_turing`에는 관련 세부 정보가 있습니다.이러한 장치를 설계하는 이유 중 하나는 더 작은 칩을 허용하고 수율 문제를 처리하기 위해 필요에 따라 개별 블록을 추가하거나 제거 할 수 있기 때문입니다 (결함이있는 모듈이 활성화되지 않을 수 있음).다행히도 이러한 장치를 프로그래밍하는 것은 CUDA 및 프레임 워크 코드 계층 아래의 일반 딥 러닝 연구원에게 숨겨져 있습니다.특히 사용 가능한 리소스가 있으면 둘 이상의 프로그램이 GPU에서 동시에 실행될 수 있습니다.그럼에도 불구하고 장치 메모리에 맞지 않는 모델을 선택하지 않으려면 장치의 한계를 인식하는 것이 좋습니다. 

![NVIDIA Turing architecture (image courtesy of NVIDIA)](../img/turing.png)
:width:`350px`
:label:`fig_turing`

더 자세히 언급 할 가치가있는 마지막 측면은*텐서 코어*입니다.이는 딥 러닝에 특히 효과적인 최적화된 회로를 추가하는 최근 추세의 예입니다.예를 들어, TPU는 빠른 매트릭스 곱셈을 위해 수축기 어레이 :cite:`Kung.1988`를 추가했습니다.여기서 설계는 대규모 작업의 매우 적은 수 (1 세대 TPU에 대해 하나) 를 지원하는 것이 었습니다.텐서 코어는 다른 쪽 끝에 있습니다.이 행렬은 수치 정밀도에 따라 $4 \times 4$과 $16 \times 16$ 사이의 행렬을 포함하는 소규모 연산에 최적화되어 있습니다. :numref:`fig_tensorcore`는 최적화에 대한 개요를 제공합니다. 

![NVIDIA tensor cores in Turing (image courtesy of NVIDIA).](../img/tensorcore.jpg)
:width:`400px`
:label:`fig_tensorcore`

계산을 최적화 할 때 우리는 결국 특정 타협을 하게 됩니다.그중 하나는 GPU가 인터럽트와 스파스 데이터를 잘 처리하지 못한다는 것입니다.[Gunrock](https_://github.com/gunrock/gunrock) :cite:`Wang.Davidson.Pan.ea.2016`) 과 같은 주목할 만한 예외가 있지만 희소 행렬 및 벡터의 액세스 패턴은 GPU가 뛰어난 고대역폭 버스트 읽기 작업과 잘 맞지 않습니다.두 목표를 모두 맞추는 것은 활발한 연구 영역입니다.예를 들어, 그래프의 딥러닝을 위해 조정된 라이브러리인 [DGL](http://dgl.ai)를 참조하십시오. 

## 네트워크 및 버스

단일 장치가 최적화를 위해 충분하지 않을 때마다 처리를 동기화하기 위해 장치에서 데이터를 송수신해야 합니다.네트워크와 버스가 편리한 곳입니다.대역폭, 비용, 거리 및 유연성과 같은 다양한 설계 매개 변수가 있습니다.한쪽 끝에는 범위가 꽤 좋고 사용하기 쉽고 (결국 전선이 없음) 저렴하지만 비교적 평범한 대역폭과 대기 시간을 제공하는 WiFi가 있습니다.올바른 생각을 가진 기계 학습 연구원은 서버 클러스터를 구축하는 데 사용하지 않을 것입니다.다음에서는 딥 러닝에 적합한 상호 연결에 중점을 둡니다. 

* **PCIe**는 레인당 매우 높은 대역폭의 지점 간 연결 (16레인 슬롯의 PCIe 4.0에서 최대 32Gb/s) 을 위한 전용 버스입니다.대기 시간은 한 자릿수 마이크로초 (5μs) 정도입니다.PCIe 링크는 소중합니다.프로세서는 제한된 수만 있습니다. AMD의 EPYC 3에는 128 레인이 있고 인텔의 제온은 칩당 최대 48 개의 레인을 가지고 있습니다. 데스크탑 급 CPU의 경우 숫자는 각각 20 (Ryzen 9) 과 16 (코어 i9) 입니다.GPU에는 일반적으로 16개의 레인이 있으므로 전체 대역폭에서 CPU에 연결할 수 있는 GPU 수가 제한됩니다.결국 스토리지 및 이더넷과 같은 다른 고 대역폭 주변 장치와 링크를 공유해야합니다.RAM 액세스와 마찬가지로 패킷 오버헤드가 감소하므로 대량 전송이 바람직합니다.
* **이더넷**은 컴퓨터를 연결하는 데 가장 일반적으로 사용되는 방법입니다.PCIe보다 훨씬 느리지 만 설치가 매우 저렴하고 탄력적이며 훨씬 먼 거리를 커버합니다.저급 서버의 일반적인 대역폭은 1Gbit/s입니다. 고급 장치 (예: 클라우드의 [C5 instances](https://aws.amazon.com/ec2/instance-types/c5/)) 는 10~100Gbit/s 대역폭을 제공합니다.이전의 모든 경우와 마찬가지로 데이터 전송에는 상당한 오버헤드가 있습니다.원시 이더넷을 직접 사용하지 않고 물리적 상호 연결 위에서 실행되는 프로토콜 (예: UDP 또는 TCP/IP) 을 사용합니다.이로 인해 오버헤드가 추가됩니다.PCIe와 마찬가지로 이더넷은 컴퓨터와 스위치와 같은 두 장치를 연결하도록 설계되었습니다.
* **스위치**를 사용하면 모든 장치 쌍이 (일반적으로 전체 대역폭) 지점 간 연결을 동시에 수행 할 수있는 방식으로 여러 장치를 연결할 수 있습니다.예를 들어 이더넷 스위치는 높은 횡단면 대역폭에서 40대의 서버를 연결할 수 있습니다.스위치는 기존 컴퓨터 네트워크에 고유하지 않습니다.PCIe 레인도 [switched](https://www.broadcom.com/products/pcie-switches-bridges/pcie-switches)가 될 수 있습니다.예를 들어, [P2 instances](https://aws.amazon.com/ec2/instance-types/p2/)의 경우처럼 많은 수의 GPU를 호스트 프로세서에 연결할 때 발생합니다.
* **NVLink**는 매우 높은 대역폭 상호 연결과 관련하여 PCIe의 대안입니다.링크당 최대 300Gbit/s의 데이터 전송 속도를 제공합니다.서버 GPU (Volta V100) 에는 6개의 링크가 있는 반면 소비자용 GPU (RTX 2080 Ti) 는 100Gbit/s 속도로 작동하는 링크가 하나만 있습니다.GPU 간에 높은 데이터 전송을 달성하려면 [NCCL](https://github.com/NVIDIA/nccl)를 사용하는 것이 좋습니다.

## 더 많은 지연 시간

:numref:`table_latency_numbers` 및 :numref:`table_latency_numbers_tesla`의 요약은 업데이트된 버전의 숫자를 [GitHub gist](https://gist.github.com/eshelman/343a1c46cb3fba142c1afdcdeec17646)로 유지 관리하는 [Eliot Eshelman](https://gist.github.com/eshelman)의 요약입니다. 

:일반적인 대기 시간 숫자입니다. 

| Action | Time | Notes |
| :----------------------------------------- | -----: | :---------------------------------------------- |
| L1 cache reference/hit                     | 1.5 ns | 4 cycles                                        |
| Floating-point add/mult/FMA                | 1.5 ns | 4 cycles                                        |
| L2 cache reference/hit                     |   5 ns | 12 ~ 17 cycles                                  |
| Branch mispredict                          |   6 ns | 15 ~ 20 cycles                                  |
| L3 cache hit (unshared cache)              |  16 ns | 42 cycles                                       |
| L3 cache hit (shared in another core)      |  25 ns | 65 cycles                                       |
| Mutex lock/unlock                          |  25 ns |                                                 |
| L3 cache hit (modified in another core)    |  29 ns | 75 cycles                                       |
| L3 cache hit (on a remote CPU socket)      |  40 ns | 100 ~ 300 cycles (40 ~ 116 ns)                  |
| QPI hop to a another CPU (per hop)         |  40 ns |                                                 |
| 64MB memory ref. (local CPU)          |  46 ns | TinyMemBench on Broadwell E5-2690v4             |
| 64MB memory ref. (remote CPU)         |  70 ns | TinyMemBench on Broadwell E5-2690v4             |
| 256MB memory ref. (local CPU)         |  75 ns | TinyMemBench on Broadwell E5-2690v4             |
| Intel Optane random write                  |  94 ns | UCSD Non-Volatile Systems Lab                   |
| 256MB memory ref. (remote CPU)        | 120 ns | TinyMemBench on Broadwell E5-2690v4             |
| Intel Optane random read                   | 305 ns | UCSD Non-Volatile Systems Lab                   |
| Send 4KB over 100 Gbps HPC fabric          |   1 μs | MVAPICH2 over Intel Omni-Path                   |
| Compress 1KB with Google Snappy            |   3 μs |                                                 |
| Send 4KB over 10 Gbps ethernet             |  10 μs |                                                 |
| Write 4KB randomly to NVMe SSD             |  30 μs | DC P3608 NVMe SSD (QOS 99% is 500μs)            |
| Transfer 1MB to/from NVLink GPU            |  30 μs | ~33GB/s on NVIDIA 40GB NVLink                 |
| Transfer 1MB to/from PCI-E GPU             |  80 μs | ~12GB/s on PCIe 3.0 x16 link                  |
| Read 4KB randomly from NVMe SSD            | 120 μs | DC P3608 NVMe SSD (QOS 99%)                     |
| Read 1MB sequentially from NVMe SSD        | 208 μs | ~4.8GB/s DC P3608 NVMe SSD                    |
| Write 4KB randomly to SATA SSD             | 500 μs | DC S3510 SATA SSD (QOS 99.9%)                   |
| Read 4KB randomly from SATA SSD            | 500 μs | DC S3510 SATA SSD (QOS 99.9%)                   |
| Round trip within same datacenter          | 500 μs | One-way ping is ~250μs                          |
| Read 1MB sequentially from SATA SSD        |   2 ms | ~550MB/s DC S3510 SATA SSD                    |
| Read 1MB sequentially from disk            |   5 ms | ~200MB/s server HDD                           |
| Random Disk Access (seek+rotation)         |  10 ms |                                                 |
| Send packet CA->Netherlands->CA            | 150 ms |                                                 |
:label:`table_latency_numbers`

:엔비디아 테슬라 GPU의 레이턴시 수치 

| Action | Time | Notes |
| :------------------------------ | -----: | :---------------------------------------- |
| GPU Shared Memory access        |  30 ns | 30~90 cycles (bank conflicts add latency) |
| GPU Global Memory access        | 200 ns | 200~800 cycles                            |
| Launch CUDA kernel on GPU       |  10 μs | Host CPU instructs GPU to start kernel    |
| Transfer 1MB to/from NVLink GPU |  30 μs | ~33GB/s on NVIDIA 40GB NVLink           |
| Transfer 1MB to/from PCI-E GPU  |  80 μs | ~12GB/s on PCI-Express x16 link         |
:label:`table_latency_numbers_tesla`

## 요약

* 장치에는 작동에 대한 오버헤드가 있습니다.따라서 많은 작은 전송보다는 적은 수의 대규모 전송을 목표로하는 것이 중요합니다.이는 RAM, SSD, 네트워크 및 GPU에 적용됩니다.
* 벡터화는 성능의 핵심입니다.액셀러레이터의 특정 능력을 알고 있는지 확인하십시오.예를 들어 일부 인텔 제온 CPU는 INT8 작업에 특히 적합하고 엔비디아 볼타 GPU는 FP16 매트릭스 매트릭스 연산에 탁월하며 엔비디아 튜링은 FP16, INT8 및 INT4 작업에서 빛을 발합니다.
* 작은 데이터 유형으로 인한 수치 오버플로는 훈련 중에 문제가 될 수 있으며 추론 중에는 문제가 될 수 있습니다.
* 앨리어싱은 성능을 크게 저하시킬 수 있습니다.예를 들어 64비트 CPU의 메모리 정렬은 64비트 경계를 기준으로 수행해야 합니다.GPU에서는 컨볼루션 크기를 텐서 코어와 같이 정렬된 상태로 유지하는 것이 좋습니다.
* 알고리즘을 하드웨어 (예: 메모리 공간 및 대역폭) 에 일치시킵니다.매개 변수를 캐시에 피팅하면 큰 속도 향상 (몇 배) 을 얻을 수 있습니다.
* 실험 결과를 확인하기 전에 종이에 새로운 알고리즘의 성능을 스케치하는 것이 좋습니다.크기 순서 이상의 불일치가 우려되는 이유입니다.
* 프로파일러를 사용하여 성능 병목 현상을 디버깅합니다.
* 교육 및 추론 하드웨어는 가격과 성능 측면에서 서로 다른 스위트 스팟을 가지고 있습니다.

## 연습문제

1. C 코드를 작성하여 외부 메모리 인터페이스와 관련하여 정렬되거나 정렬되지 않은 메모리에 액세스하는 것 사이에 속도에 차이가 있는지 테스트합니다.힌트: 캐싱 효과에 주의하세요.
1. 순서대로 메모리에 액세스하거나 주어진 보폭으로 메모리에 액세스하는 것 사이의 속도 차이를 테스트합니다.
1. CPU의 캐시 크기를 어떻게 측정할 수 있을까요?
1. 대역폭을 최대화하기 위해 여러 메모리 채널에 데이터를 어떻게 배치하시겠습니까?작은 실이 많으면 어떻게 배치하겠습니까?
1. 엔터프라이즈급 HDD가 10,000rpm으로 회전하고 있습니다.HDD가 데이터를 읽기 전에 최악의 경우를 소비하는 데 필요한 최소 시간은 얼마입니까 (헤드가 거의 순간적으로 움직인다고 가정 할 수 있음)?2.5인치 HDD가 상용 서버 (3.5인치 및 5.25인치 드라이브 기준) 에 널리 사용되는 이유는 무엇입니까?
1. HDD 제조업체에서 저장 밀도를 제곱인치당 1Tbit에서 제곱인치당 5Tbit로 늘린다고 가정합니다.2.5인치 HDD의 링에 얼마나 많은 정보를 저장할 수 있습니까?내부 트랙과 외부 트랙 사이에 차이가 있나요?
1. 8비트에서 16비트 데이터 유형으로 이동하면 실리콘의 양이 약 4배 증가합니다.왜요?NVIDIA가 튜링 GPU에 INT4 작업을 추가한 이유는 무엇입니까?
1. 메모리를 통해 앞으로 읽는 것보다 뒤로 읽는 것이 얼마나 빠릅니까?이 숫자는 컴퓨터와 CPU 공급업체마다 다릅니까?왜요?C 코드를 작성하고 실험해 보십시오.
1. 디스크의 캐시 크기를 측정할 수 있습니까?일반적인 HDD의 경우 무엇입니까?SSD에 캐시가 필요한가요?
1. 이더넷을 통해 메시지를 보낼 때 패킷 오버헤드를 측정합니다.UDP와 TCP/IP 연결의 차이점을 찾아보십시오.
1. 직접 메모리 액세스를 사용하면 CPU 이외의 장치가 메모리에 직접 쓰기 (읽기) 할 수 있습니다.이게 왜 좋은 생각일까요?
1. 튜링 T4 GPU의 성능 수치를 살펴보십시오.FP16에서 INT8 및 INT4로 전환함에 따라 성능이 “유일한”두 배가되는 이유는 무엇입니까?
1. 샌프란시스코와 암스테르담 간 왕복 여행에서 패킷을 보내는 데 걸리는 최단 시간은 언제입니까?힌트: 거리가 10,000km라고 가정 할 수 있습니다.

[Discussions](https://discuss.d2l.ai/t/363)
